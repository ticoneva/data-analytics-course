{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301b2556-3c62-4c06-9ae6-0ee028c660ea",
   "metadata": {},
   "source": [
    "# Accessing a Generative AI Model through OpenAI API\n",
    "\n",
    "Version: 2025-10-5\n",
    "\n",
    "Generative AI models are machine learning models that are capable of generating content.\n",
    "This notebook is going to focus on the most commonly-used type of generative AI models&mdash;the \n",
    "ones that generate text. These models are called *large language models*, or 'LLM' for short.\n",
    "We will not be going into the technical details of how a LLM works at this moment, but rather focus\n",
    "on how to use an LLM as an end user.\n",
    "\n",
    "### A. Accessing an LLM through Python\n",
    "Although it is very convenient to access an LLM through a browser interface for one-off task, \n",
    "for repetitive task you will generating want to access the model using a program. Model providers \n",
    "will generally provide such access through an *application programming interface*, or 'API' for short.\n",
    "An API defines what sorts of interactions are possible with the model, and how input and output data \n",
    "should look like. \n",
    "\n",
    "The API used by OpenAI, the provider of ChatGPT, is the de facto standard supported by most models.\n",
    "\n",
    "The first step is to set up an OpenAI client. The client requires two piece of information:\n",
    "1. `base_url`: this is the web address of the model provider. If you use OpenAI's model, this can be omited.\n",
    "2. `api_key`: this is a string of text unique to your user account with the model provider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff1848-d882-403f-888d-3799ef0bf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fd7e0-4945-4c8a-b480-6898c797bd8a",
   "metadata": {},
   "source": [
    "In a production environment, it is best to save this piece of information as an environment variable, so that it will not be saved in your notebook. The easiest way to do so when working in a Jupyter notebook is to put the key in a filed named `.env`, then use the `dotenv` library to set the environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa489c-056f-4e24-ae3a-32ab7946d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file containing environment variables.\n",
    "# Default is to look for it in the current working directory.\n",
    "\n",
    "\n",
    "# The API key should be saved as an environment variable OPENAI_API_KEY\n",
    "# Optionally set the base_url as OPENAI_BASE_URL in the same file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd43909-469a-4975-9980-b1a4e1d1660b",
   "metadata": {},
   "source": [
    "### B. Model List\n",
    "\n",
    "To see what models the provider support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d76bd6-d461-41e9-aaa7-d7403713eec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e206c5-cc8c-46b9-8297-f63097b21ce7",
   "metadata": {},
   "source": [
    "### C. Calling the Model\n",
    "\n",
    "To call a model, use \n",
    "```python\n",
    "response = client.chat.completions.create(...)\n",
    "```\n",
    "You will need to provide a few pieces of information:\n",
    "- `model`: the name of the model.\n",
    "- `messages`: a list containing the conversation history. Each message should be dictionary with a `role` and a `content`. `role` can be one of:\n",
    "    - `system`: system prompt. Use this to give the model general guidelines that it should follow strictly.\n",
    "    - `user`: prompt entered by the user. \n",
    "    - `assistant`: response from the model. \n",
    "    - `tool`: response from tools the model can use.\n",
    "- Additional settings such as temperature and number of samples:\n",
    "    - `temperature`: Adjust the randomness of the response. 0 is the lowest setting.\n",
    "      Default is model specfic, around 0.6-0.8.\n",
    "    - `n`: number of responses you want the model to generate. Default is 1.\n",
    "\n",
    "The response will be recorded in\n",
    "```python\n",
    "response.choices[0].message.content\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e23de-39e8-43a4-8171-29c645e69996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c5b33-7762-4625-aecb-e5d5d140566f",
   "metadata": {},
   "source": [
    "### D. Example: Scrapping Webpage and Extract Information with LLM\n",
    "\n",
    "We first scrape the webpage with Selenium + Beautiful Soup,\n",
    "but unlike before, we do not manually find the elements we need.\n",
    "Instead, we export a stripped version of the webpage's source code,\n",
    "then uses an LLM to extract the information we need. \n",
    "\n",
    "Because LLMs can only process a limited amount of text input, called \n",
    "*context length*, and slows down as the context length goes up, \n",
    "it is usually wise to use Beautiful Soup to locate\n",
    "as precious as possible what you need, before passing the source code\n",
    "to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69785aa2-92dc-4c8e-8647-88ff2a14d216",
   "metadata": {},
   "source": [
    "Scrape the webpage in full:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d48133c6-545a-4fa0-ba8a-e049eda315eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works with static content.\n",
    "# See A6-Data-Scrping-Completed for a version that works with dynamic content.\n",
    "import requests\n",
    "def get_page_source(url, strip=False):\n",
    "    # Function to access a page and save all horses into a list\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    return soup.get_text(strip=strip)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffea03-c586-4daa-92bb-451fbcb5d6c1",
   "metadata": {},
   "source": [
    "Now we feed the source code to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c243c3-ed62-4837-a169-b2ac2e6cd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80410e65-5d5f-4091-92ba-d41e55b19d10",
   "metadata": {},
   "source": [
    "You can strip white space by setting `strip = True` in `get_page_source()`, \n",
    "but it appears to drastically lower the quality of the LLM's output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81755146-1f7f-407f-9ac4-d3fd299e9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "page_source = get_page_source('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST',\n",
    "                              strip=True)\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "start = time.time()\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"The following webpage contains horse racing results. \n",
    "                                Please extract the result table and return it in comma-delimited\n",
    "                                CSV format. No explanation is needed.\n",
    "                                {page_source}\n",
    "                                \"\"\"},\n",
    "  ],\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "print(\"Processing took: {:.2f}\".format(time.time() - start))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e406271e-0726-4a5d-be16-e4c211093c3c",
   "metadata": {},
   "source": [
    "To speed up the processing and make the model's output more accurate, you can use Beauitful Soup to locate the table, and provide only the source code of the table to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609d26e-d36e-4d2f-88b5-3591cb836fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cf98104-4828-49c8-97fe-9ceb382c4202",
   "metadata": {},
   "source": [
    "Let us try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68f8c9c2-b97a-49f4-8d38-48b9c5fb3de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing took: 12.99\n",
      "Pla.,Horse No.,Horse,Jockey,Trainer,Act. Wt.,Declar. Horse Wt.,Dr.,LBW,Running Position,Finish Time,Win Odds\n",
      "1,10,JOLLY JOLLY,K Teetan,P O'Sullivan,114,1214,13,-,\"1 1 1 1\",1:22.05,2.6\n",
      "2,8,PEOPLE'S KNIGHT,T Berry,J Moore,119,1163,8,2,\"2 4 2 2\",1:22.39,5.7\n",
      "3,12,RUN FORREST,J Moreira,C S Shum,115,1135,10,3,\"14 10 10 3\",1:22.54,3.9\n",
      "4,4,MODERN TSAR,B Prebble,W Y So,123,1101,11,4-3/4,\"9 13 13 4\",1:22.80,13\n",
      "5,3,MAGNETISM,G Lerena,D E Ferraris,125,1130,3,4-3/4,\"7 6 6 5\",1:22.81,52\n",
      "6,1,ENORMOUS HONOUR,N Rawiller,Y S Tsui,131,1127,9,5-1/4,\"11 12 12 6\",1:22.87,10\n",
      "7,9,HAPPY JOURNEY,H W Lai,S Woods,114,1040,5,6-1/2,\"5 7 7 7\",1:23.08,121\n",
      "8,14,WINGOLD,M L Yeung,A Lee,111,1154,12,6-1/2,\"13 14 14 8\",1:23.11,331\n",
      "9,11,OVETT,H N Wong,A T Millard,105,1153,4,7-1/4,\"3 2 3 9\",1:23.20,41\n",
      "10,5,PAKISTAN BABY,D Whyte,A S Cruz,121,1023,7,7-1/4,\"6 11 11 10\",1:23.22,12\n",
      "11,6,SUPER FLUKE,M Demuro,D Cruz,120,1109,14,7-3/4,\"4 3 4 11\",1:23.27,65\n",
      "12,7,JUN GONG,C Y Ho,C H Yip,115,1147,6,10-1/4,\"10 9 8 12\",1:23.68,83\n",
      "13,2,LAUGH OUT LOUD,G Mosse,K L Man,126,1127,1,10-1/2,\"8 5 5 13\",1:23.73,15\n",
      "14,13,TEN SPEED,Y T Cheng,C W Chang,116,1033,2,12-3/4,\"12 8 9 14\",1:24.08,202\n"
     ]
    }
   ],
   "source": [
    "page_source = get_page_source('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST',\n",
    "                              strip=True)\n",
    "start = time.time()\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"The following webpage contains horse racing results. \n",
    "                                Please extract the result table and return it in comma-delimited\n",
    "                                CSV format. No explanation is needed.\n",
    "                                {page_source}\n",
    "                                \"\"\"},\n",
    "  ],\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "print(\"Processing took: {:.2f}\".format(time.time() - start))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa751c-3734-489f-95ee-15f77c988107",
   "metadata": {},
   "source": [
    "Finally, we write the output to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae1ba1-2ad7-4150-9b2b-3c1651b26031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result.csv\", \"a\") as f:\n",
    "  f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3f309-01ff-4d4d-8ba6-74c47208ac51",
   "metadata": {},
   "source": [
    "### E. Outputing to File\n",
    "\n",
    "Because the LLM has done the formatting, we directly write\n",
    "the output to file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b355f1-4277-4988-aa72-7782e1a9b024",
   "metadata": {},
   "source": [
    "### F. Scrape Multiple Pages\n",
    "\n",
    "We can put everything together in one function\n",
    "and use it in a loop to save the information we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad9173-f885-4a57-b560-3bcf152c22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape results\n",
    "\n",
    "def scrape_webpage(url, prompt):\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf2993-9d6b-4521-bd90-a68834c67db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first part of the URL of data source\n",
    "url_front = \"http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/\"\n",
    "prompt = \"\"\"The following webpage may contain horse racing results in a table. \n",
    "            If it does, please extract the result table and return it in \n",
    "            comma-delimited CSV format. If not, just return an empty string.\n",
    "            No explanation is needed.\n",
    "            \"\"\"\n",
    "\n",
    "# Copy the loop from above and incorporate the csv-saving code\n",
    "for year in range(2017,2018):\n",
    "    for month in range(1,2):\n",
    "        for day in range(1,15):\n",
    "            \n",
    "            # Convert month and day to 2-digit representation\n",
    "            month_2d = '{:02d}'.format(month)\n",
    "            day_2d = '{:02d}'.format(day)\n",
    "            \n",
    "            # Full URL of data source\n",
    "            url = url_front + str(year) + month_2d + day_2d\n",
    "            \n",
    "            # Print the URL so we know the progress so far\n",
    "            print(\"Trying:\",url)\n",
    "            \n",
    "            # Call our function to fetch and process data given the URL\n",
    "            output = scrape_webpage(url, prompt)\n",
    "            \n",
    "            # Only save if there is something in content\n",
    "            if output is not None:\n",
    "                filepath = str(year)+month_2d+day_2d+\".csv\"\n",
    "                \n",
    "                # Save to file\n",
    "                with open(filepath, \"w\") as f:\n",
    "                    f.write(output)\n",
    "                    print(f\"{filepath} saved.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
