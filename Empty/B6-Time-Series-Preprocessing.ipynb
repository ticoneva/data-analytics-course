{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Processing\n",
    "\n",
    "Version: 2022-10-13\n",
    "\n",
    "In this notebook, we will cover how to process time series data. \n",
    "\n",
    "\n",
    "### A. Data\n",
    "\n",
    "First let us load the data. We will use Hang Seng Index data from a csv file, \n",
    "but in practice you will probably want to pull the data with\n",
    "a library such as `yfinance`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import stock data and keep only two variables\n",
    "stock_data = pd.read_csv(\"../Data/hsi.csv\")\n",
    "stock_data.head(36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will will only keep the date and adjusted closing price.\n",
    "We will also drop any samples with missing values.\n",
    "- To drop rows with missing values:\n",
    "```python\n",
    "df.dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only two columns and drop missing\n",
    "\n",
    "\n",
    "# Show the data\n",
    "stock_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Datetime Index\n",
    "\n",
    "We now carry out several time-series-specific operations:\n",
    "- Convert the date to pandas **datatime** format, use ```pd.to_datetime()```.\n",
    "  You can then extract individual date components by ```.dt.year```, ```.dt.month``` etc.\n",
    "  For example, to extract year out of a column called *date*, you can write:\n",
    "  ```python\n",
    "  df['date'] = pd.to_datetime(df('date'))\n",
    "  df['year'] = df('date').dt.year \n",
    "  ```\n",
    "- Set the date as index. This allows the use of time-series-specific features.\n",
    "```python\n",
    "df.index = pd.DatetimeIndex(df['date_column'])\n",
    "```\n",
    "- Fill in missing dates:\n",
    "```python\n",
    "df.asfreq(freq,method)\n",
    "```\n",
    "where `freq` is the desired frequency and `method` is how the columns of newly inserted dates should be filled. \n",
    "    \n",
    "    See [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases) for a list of valid frequency.\n",
    "    \n",
    "    The default `method` is `None`, which means the newly inserted dates' columns have missing values. \n",
    "    You can choose instead to propagate last valid observation forward (`method='pad'`) or use the next valid observation (`method='backfill'`).\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to pandas datetime format\n",
    "\n",
    "\n",
    "# Use date as the index of the dataframe\n",
    "\n",
    "\n",
    "# Show the data\n",
    "stock_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing dates\n",
    "\n",
    "\n",
    "# Show the data\n",
    "stock_filled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. What Do You Want to Model?\n",
    "\n",
    "Next we have to decide what we want to model. Finance research mostly work with returns instead of price for a variety of reasons, but chief among those is the fact that return is stationary while price is usually not. \n",
    "\n",
    "More generally, when you model time series, you should consider whether you want to model:\n",
    "- The original time series $x_t$\n",
    "- First difference $x_t - x_{t-1}$\n",
    "- Percentage change  $\\frac{x_t - x_{t-1}}{x_{t-1}}$ \n",
    "- Direction of movement $\\unicode{x1D7D9}\\left[ x_t - x_{t-1} > 0 \\right]$\n",
    "\n",
    "This decision is important because it affects what models you can use and how well they might perform. For example, modelling direction of movement is a classification task, while the other three options are regression tasks.\n",
    "\n",
    "The pandas technique we use here is ```.shift(x)```. \n",
    "This method shifts all rows down by *x* rows.\n",
    "The nice thing about this technique is that you can totally do things\n",
    "like \n",
    "```python\n",
    "stock_data[\"Price\"]/stock_data.shift(1)[\"Price\"] - 1\n",
    "```\n",
    "which gives you all daily return in one single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change in index\n",
    "\n",
    "\n",
    "# Direction of movement\n",
    "\n",
    "\n",
    "# Return since the previous day\n",
    "\n",
    "\n",
    "# 90-day future return\n",
    "\n",
    "\n",
    "# Show the data\n",
    "stock_filled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `.shift()` does not take into consideration the nature of the index. If you have gaps in your data, what you get might not be want you intend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate return without first filling missing dates\n",
    "# We get return since previous trading day\n",
    "\n",
    "\n",
    "# Show the data\n",
    "stock_filled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, maybe we do want return for a given number of trading days instead of return for a given number of calendar days. We can fill in the missing dates after we compute all the necessary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Lag Terms\n",
    "\n",
    "In time series modelling we often include lag terms. Some models such as statsmodel's `ARMA` will compute the lag terms for you, but some others will not. If you need lag term for your model, you can also generate it with `.shift()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate four period lag terms\n",
    "\n",
    "\n",
    "# Show the data\n",
    "stock_filled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try fitting some models. First, an ARIMA from `statsmodels`. We only need to provide the variable we want to model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# ARIMA will complain if we do not set frequency\n",
    "stock_filled = stock_data.asfreq('D')\n",
    "arma = ARIMA(stock_filled[\"Adj Close\"], order=(4, 0, 0)).fit()\n",
    "arma.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use a non-time-series-specific model like lasso, we will need the manually-created lag terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "\n",
    "# Create a copy of data with no missing values\n",
    "\n",
    "#Run a lasso regression\n",
    "\n",
    "\n",
    "#Coefficients\n",
    "print(\"Coefficients:\",model.coef_)\n",
    "print(\"Intecept:\",model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Changing Frequency and Rolling Window\n",
    "\n",
    "You can change the frequency of the data with `pd.resample(freq).ops()`. For example, to get the weekly average return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly average return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another technique is `pd.rolling().ops`, which applies an operation for each sample across a rolling window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling 7-trading-day average\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Walk Forward Split\n",
    "\n",
    "When working with time series data we need to ensure the training data comes before the validation and test data. Instead of randomly splitting the data, what we want is this:\n",
    "\n",
    "![walk-forward-split](https://i.stack.imgur.com/padg4.gif)\n",
    "\n",
    "The defining features are:\n",
    "1. Test data must comes from a later date than training data.\n",
    "2. Test data in each split do not overlap. \n",
    "\n",
    "Scikit-learn's `TimeSeriesSplit` can produce such splits:\n",
    "```python\n",
    "tscv = TimeSeriesSplit(n_splits, max_train_size)\n",
    "for train_index, test_index in tscv.split(merged_data):\n",
    "    # do something\n",
    "```\n",
    "Options:\n",
    "- `n_splits` controls the number of splits returned. The default is 5 splits. You probably want more if you have very long time series.\n",
    "- `max_train_size` specifies the maximum number of training samples in a split. The default is `None`, which means there is no limit. This also means by default each subsequent split will be longer than before, so specify this number if you want the splits to have equal size.  \n",
    "\n",
    "**It is important note that walk-forward split as implemented by `TimeSeriesSplit` is *deterministic*---same data and same settings means the same split, everytime.** This is the nature of walk-forward split, and more generally the use of historical data for backtesting. There is a real chance of overfitting, because there is no guarantee that history will repeat itself in the exact same way.\n",
    "\n",
    "Because `tscv.split()` returns *indexes*, you are responsible for fetching the data according to the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# 5 splits with 14 days of training data in each split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists are quite long, so they are hard to see. Let us just print their range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# 5 splits with 14 days of training data in each split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fetch the actual data, use `df.iloc[list_of_indexes]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the actual data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us put everything together for cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict tomorrow's stock price with past four days of stock price\n",
    "# Specify number of splits here\n",
    "n_splits = 20\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# Drop any observation with missing columns\n",
    "data = stock_data.dropna()\n",
    "\n",
    "# Data\n",
    "y = data[[\"Adj Close\"]]\n",
    "X = data[[\"ac_1\",\"ac_2\",\"ac_3\",\"ac_4\"]]\n",
    "\n",
    "# Setup models\n",
    "lasso = Lasso(alpha=500)\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# List to store scores and predictions\n",
    "oos_score_list = []\n",
    "prediction_list = []\n",
    "\n",
    "print(\"Split  In-sample R^2  Out-of-Sample R^2\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Loop through the splits. Run a Lasso Regression for each split.\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    \n",
    "    # Fetch data based on split\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    lasso.fit(X_train,y_train)\n",
    "    \n",
    "    # Record score and prediction\n",
    "    oos_score = lasso.score(X_test,y_test)\n",
    "    oos_score_list.append(oos_score)\n",
    "    prediction = lasso.predict(X_test)\n",
    "    prediction_list.append(prediction)\n",
    "    \n",
    "    print(str(i).center(5),\n",
    "          str(round(lasso.score(X_train,y_train),2)).center(13),\n",
    "          str(round(oos_score,2)).center(13)\n",
    "         )\n",
    "    \n",
    "print(\"-\"*40)\n",
    "print(\"Average out-of-sample score:\",round(np.mean(oos_score_list),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the actual index versus the predicted index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicted index, actual index and corresponding dates\n",
    "# Since predicted index is shorter than the actual index, we have to cut the latter\n",
    "prediction = np.asarray(prediction_list).flatten()\n",
    "actual = y[-1*len(prediction):].to_numpy() \n",
    "dates = data[\"Date\"].to_numpy()\n",
    "dates = dates[-1*len(prediction):]\n",
    "\n",
    "# Line Chart\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dates,prediction,label=\"predict\") #First line\n",
    "plt.plot(dates,actual,label=\"actual\") #Second line\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5) #Size\n",
    "plt.legend() #Show legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two series look pretty close. Unfortunately, the chart is actually quite misleading. Let us see why in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. What Do You Want to Model? (Cont'd)\n",
    "\n",
    "The out-of-sample score and the line chart from above might seem to suggest that our model of Hang Seng Index works quite well. We will now see why that is in fact not the case. \n",
    "\n",
    "Let us zoom into the line chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only the last 90 observations\n",
    "prediction = np.asarray(prediction_list).flatten()\n",
    "prediction = prediction[-90:]\n",
    "actual = y[-1*len(prediction):].to_numpy()\n",
    "dates = data[\"Date\"].to_numpy()\n",
    "dates = dates[-1*len(prediction):]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dates,prediction,label=\"predict\")\n",
    "plt.plot(dates,actual,label=\"actual\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see the issue&mdash;the predicted index is basically the actual index lagged by one period. We can hardly call this a useful prediction. There is a reason why using a non-stationary time series as the target is problematic.\n",
    "\n",
    "Let us try modelling return, first difference and direction of movement instead. Exact same design, just different variables. You will see they all perform very poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict tomorrow's stock return with past four days of stock return\n",
    "# Specify number of splits here\n",
    "n_splits = 20\n",
    "\n",
    "# Generate four period lag terms for return\n",
    "for t in range(1,5):\n",
    "    stock_data[\"dr_\"+str(t)] = stock_data[\"daily_return\"].shift(t)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "data = stock_data.dropna()\n",
    "\n",
    "y = data[[\"daily_return\"]]\n",
    "X = data[[\"dr_1\",\"dr_2\",\"dr_3\",\"dr_4\"]]\n",
    "lasso = Lasso(alpha=0.0001)\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "oos_score_list = []\n",
    "prediction_list = []\n",
    "\n",
    "# Loop through the splits. Run a Lasso Regression for each split.\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    \n",
    "    # Fetch data based on split\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    lasso.fit(X_train,y_train)\n",
    "    \n",
    "    # Record score and prediction\n",
    "    oos_score = lasso.score(X_test,y_test)\n",
    "    oos_score_list.append(oos_score)\n",
    "    prediction = lasso.predict(X_test)\n",
    "    prediction_list.append(prediction)\n",
    "    \n",
    "print(\"Average out-of-sample score:\",round(np.mean(oos_score_list),2))    \n",
    "\n",
    "# Chart\n",
    "prediction = np.asarray(prediction_list).flatten()\n",
    "prediction = prediction[-90:]\n",
    "actual = y[-1*len(prediction):].to_numpy()\n",
    "dates = data[\"Date\"].to_numpy()\n",
    "dates = dates[-1*len(prediction):]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dates,prediction,label=\"predict\")\n",
    "plt.plot(dates,actual,label=\"actual\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict tomorrow's first difference with past four days' first difference\n",
    "# Specify number of splits here\n",
    "n_splits = 20\n",
    "\n",
    "# Generate four period lag terms for first difference\n",
    "stock_data[\"change\"] = (stock_data[\"Adj Close\"] \n",
    "                                     - stock_data.shift(1)[\"Adj Close\"])\n",
    "for t in range(1,5):\n",
    "    stock_data[\"ch_\"+str(t)] = stock_data[\"change\"].shift(t)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "data = stock_data.dropna()\n",
    "\n",
    "y = data[[\"change\"]]\n",
    "X = data[[\"ch_1\",\"ch_2\",\"ch_3\",\"ch_4\"]]\n",
    "lasso = Lasso(alpha=0.0001)\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "oos_score_list = []\n",
    "prediction_list = []\n",
    "\n",
    "# Loop through the splits. Run a Lasso Regression for each split.\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    \n",
    "    # Fetch data based on split\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    lasso.fit(X_train,y_train)\n",
    "    \n",
    "    # Record score and prediction\n",
    "    oos_score = lasso.score(X_test,y_test)\n",
    "    oos_score_list.append(oos_score)\n",
    "    prediction = lasso.predict(X_test)\n",
    "    prediction_list.append(prediction)\n",
    "    \n",
    "print(\"Average out-of-sample score:\",round(np.mean(oos_score_list),2))    \n",
    "\n",
    "# Chart\n",
    "prediction = np.asarray(prediction_list).flatten()\n",
    "prediction = prediction[-90:]\n",
    "actual = y[-1*len(prediction):].to_numpy()\n",
    "dates = data[\"Date\"].to_numpy()\n",
    "dates = dates[-1*len(prediction):]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dates,prediction,label=\"predict\")\n",
    "plt.plot(dates,actual,label=\"actual\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict tomorrow's direction of movement with past four days' direction of movement\n",
    "# Specify number of splits here\n",
    "n_splits = 20\n",
    "\n",
    "# Generate four period lag terms for direction of movement\n",
    "stock_data[\"direction\"] = np.where(stock_data[\"change\"]>0,1,0)\n",
    "stock_data[\"direction\"] = np.where(stock_data[\"change\"].isna(),\n",
    "                                          np.nan,\n",
    "                                          stock_data[\"direction\"])\n",
    "for t in range(1,5):\n",
    "    stock_data[\"d_\"+str(t)] = stock_data[\"direction\"].shift(t)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "data = stock_data.dropna()\n",
    "\n",
    "y = data[\"direction\"]\n",
    "X = data[[\"d_1\",\"d_2\",\"d_3\",\"d_4\"]]\n",
    "model = LogisticRegression()\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "oos_score_list = []\n",
    "prediction_list = []\n",
    "\n",
    "# Loop through the splits. Run a Logistic Regression for each split.\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    \n",
    "    # Fetch data based on split\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    # Record score and prediction\n",
    "    oos_score = model.score(X_test,y_test)\n",
    "    oos_score_list.append(oos_score)\n",
    "    prediction = model.predict(X_test)\n",
    "    prediction_list.append(prediction)\n",
    "    \n",
    "print(\"Average out-of-sample score:\",round(np.mean(oos_score_list),2))    \n",
    "\n",
    "# Chart\n",
    "prediction = np.asarray(prediction_list).flatten()\n",
    "prediction = prediction[-90:]\n",
    "actual = y[-1*len(prediction):].to_numpy()\n",
    "dates = data[\"Date\"].to_numpy()\n",
    "dates = dates[-1*len(prediction):]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dates,prediction,label=\"predict\")\n",
    "plt.plot(dates,actual,label=\"actual\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
