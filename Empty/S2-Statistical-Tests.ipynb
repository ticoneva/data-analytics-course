{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests\n",
    "\n",
    "A common question we would like to answer when conducting data analysis is, how likely is the true value $b$ when the observed value is $a$? Statistical tests help us answer such a question.\n",
    "\n",
    "We will introduce two In this notebook: *Z*-test and *t*-test. They both provide an answer to the question of **how likely are we going to see our observed sample average $\\bar{X}$ when the population average is $\\mu_0$**. \n",
    "\n",
    "For both tests, the procedure is as follows:\n",
    "1. We have a value $\\mu_0$ that we think might be the population average. \n",
    "    This is called the **null hypothesis**.\n",
    "2. We construct the **test statistic**, which is a value calculated \n",
    "    from $\\mu_0$ as well as the observed sample average $\\bar{X}$. \n",
    "3. We compute the chance of seeing a test statistic at least as extreme as the one we have.\n",
    "    This chance is called the **p-value**.\n",
    "4. If the answer is unlikely, then we would *reject* the hypothesis that $\\mu_0$ is the population average.\n",
    "\n",
    "\n",
    "First let us import some standard libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. *Z*-Test\n",
    "\n",
    "A *Z*-test assumes the test statistic has a standard normal distribution. To construct the *Z*-test from scratch:\n",
    "1. First generate some random data.\n",
    "2. Calculate the sample average $\\bar{X}$ and sample standard deviation $\\hat{\\sigma}$. This is where you would actually start in practice.\n",
    "3. Calculate the test statistic:\n",
    "    $$\n",
    "    \\frac{\\bar{X} - \\mu_0}{\\hat{\\sigma}/\\sqrt{n}}\n",
    "    $$\n",
    "4. Compute the *p-value*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard normal distribution\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Generate some random numbers based on average pop_avg and std. dev. pop_sd\n",
    "\n",
    "\n",
    "# Sample average, sample standard deviation and sample size\n",
    "\n",
    "\n",
    "# Test statistic\n",
    "\n",
    "\n",
    "# p-value\n",
    "\n",
    "\n",
    "# Show results\n",
    "print(\"population average:\",pop_avg)\n",
    "print(\"-\"*40)\n",
    "print(\"sample average:    \",sample_mean)\n",
    "print(\"null hypothesis:   \",mu_0)\n",
    "print(\"test statistic:    \",z)\n",
    "print(\"p-value:           \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The norm in social sciences is to reject the null hypothesis if the p-value is smaller than 0.05.** \n",
    "This means that if the hypothesized value is indeed the true value, there is only less than 5 percent chance that we are going to see the observed value. This is deemed unlikely enough that most social scientists will conclude the hypothesized value is not the true value.\n",
    "\n",
    "**It is important to note that the rejection of the null hypothesis does not prove that the observed value equals the true value**. The observed value is your best guess, but it would be impossible to reject other values that are only slightly different from the observed value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. *t*-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student's *t*-test adjusts the distribution of the test statistic according to sample size, under the assumption that the population is normally distributed. Let us first investigate what adjustment is necessary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat 500 times, 5 data points each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 500 times, 10 data points each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 500 times, 30 data points each\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should now be clear that the smaller the sample size, the \"fatter\" the distribution of the test statistic is. This means that when sample size is small, we will see extreme test statistic more often. \n",
    "\n",
    "To account for this phenomenon, *t*-test adjusts the distribution it use to determine whether a test statistic is too extreme. This *t*-distribution requires us to provide the **degrees of freedom**, which equals to sample size - 1.\n",
    "\n",
    "Let us check out the difference between the standard normal distribution and the *t*-distribution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t distribution\n",
    "from scipy.stats import t\n",
    "\n",
    "x = np.linspace(-3,3,100)\n",
    "plt.plot(x, stats.norm.pdf(x), \n",
    "         x, stats.t.pdf(x,df=4),\n",
    "         x, stats.t.pdf(x,df=9),\n",
    "         x, stats.t.pdf(x,df=29)\n",
    "        )\n",
    "plt.legend(['std. normal','t sample size 5','t sample size 10','t sample size 30'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In elementary statistics, this adjustment is usually done for sample size smaller than 30. Beyond that the distribution is often deemed close enough to simply use the *Z*-test.\n",
    "\n",
    "We can run a t-test from scratch simply by using the *t*-distribution instead of the standard normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test p-value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Scipy\n",
    "```scipy.stats``` contains many of the common statistical tests, including *t*-test: ```scipy.stats.ttest_1samp(x,popmean)```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t-test\n",
    "from scipy.stats import ttest_1samp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
