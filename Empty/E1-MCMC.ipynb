{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Good is this Firm?\n",
    "\n",
    "You have been assigned to the private equity department for the next six months. Private equity department invests in firms that are not public listed. Part of your duty is to analyze target firms and make recommendations as to whether the firms are worth investing.\n",
    "\n",
    "You have 60 months of data from one firm. Of the 60 months, the firm had good performance in 40 and poor performance in 20. Your supervisor has asked you to analyze if the firm has potential (“good firm”) or not (“bad firm”). You believe that half the firms in the market are good and half are bad. For good firms, they have a 70% chance of achieving good performance in any given month, while for bad firms they only have 50% chance of doing so.\n",
    "\n",
    "The question is, given the data, how do you figure out the chance that the current firm is a good one?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical Solution \n",
    "\n",
    "First, let us ask a simpler question: how likely is a firm going to do well in 40 months out of 60? That is exactly what the binomial distribution tells us. Let $i$ be the type of firm, $p_i$ the chance of achieving good performance in a given month, $n$ the total number of months and $k$ the number of good months. The binomial distribution says the chance that a firm of type $i$ is going to do well in 40 months out of 60 is:\n",
    "$$\n",
    "P\\left(X \\mid i\\right)=\\begin{pmatrix} n \\\\ k \\end{pmatrix} p_i^{k} \\left(1-p_i \\right)^{n-k}\n",
    "$$\n",
    "So how likely is a good firm going to do well in 40 months out of 60? Using the formula above:\n",
    "$$\n",
    "P\\left(X \\mid G\\right)=\\begin{pmatrix} 60 \\\\ 40 \\end{pmatrix} 0.7^{40} 0.3^{20}\n",
    "$$\n",
    "We can use the excel function ```BINOM.DIST(40,60,0.7,FALSE)``` to compute the value of this expression, which turns out to be 0.0931.\n",
    "\n",
    "Similarly, the chance that a bad firm is going to do well in 40 months out of 60 is\n",
    "$$\n",
    "P\\left(X \\mid B\\right)=\\begin{pmatrix} 60 \\\\ 40 \\end{pmatrix} 0.5^{40} 0.5^{20}=0.0036\n",
    "$$\n",
    "With these two numbers, we can find the chance that the firm is a good one with Bayes Rule:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(G│X) &= \\frac{P \\left (X \\mid G \\right)P\\left(G\\right)}{P\\left(X\\right)}  \\\\ \n",
    "&=\\frac{0.0931\\times0.5}{0.0931\\times0.5+0.0036\\times0.5} \\\\\n",
    "&=0.962 \n",
    "\\end{aligned}\n",
    "$$\n",
    "So there is 96.2% chance that the firm is good. (Would you have guessed this number without going through the math?)\n",
    "\n",
    "While we were able to solve this case analytically, this is an exception rather than the norm in reality. In more difficult situation, we will have numerically approximate the chance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain Monte Carlo (MCMC) Sampling\n",
    "\n",
    "We randomly draw a firm and keep it with probability:\n",
    "$$\n",
    "\\min{\\left[1, \\frac{P\\left(X \\mid i\\right)P\\left(i\\right)}{P\\left(X \\mid c\\right)P\\left(c\\right)}\\right]}\n",
    "$$\n",
    "where $c$ is the type of the last firm we kept. Repeat this process long enough and the distribution of firms we kept will converge to the ratio we found in the analytical solution above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Simulation count\n",
    "\n",
    "#Prior P(i)\n",
    "\n",
    "#P(x|i)P(i)\n",
    "\n",
    "#MCMC\n",
    "\n",
    "#Print estimate    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside of MCMC is that it could take a long time to converge. We can see this graphically if we plot the estimates at each time step.  Even for a scenario as simple as ours, it takes more than 15000 steps before the estimate stabilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot estimate at each time step\n",
    "base = np.arange(len(x_list)) + 1\n",
    "mcmc = np.cumsum(x_list)/base\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mcmc)    \n",
    "ax.set_xlabel(\"samples\")\n",
    "ax.set_ylabel(\"estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why does this Make Sense?\n",
    "\n",
    "Let $X=\\begin{bmatrix} x_G \\\\ x_B \\end{bmatrix}$, where $x_G$ is the chance that a firm is good\n",
    "and $x_B$ is the chance that the firm is bad. \n",
    "This means, for example, \n",
    "- $X=\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ represent a firm that is certainly good,\n",
    "- $X=\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ represent a firm that is certainly bad, and\n",
    "- $X=\\begin{bmatrix} 0.6 \\\\ 0.4 \\end{bmatrix}$ represent a firm that has 60% chance of being good.\n",
    "\n",
    "We make an initial guess $X_0$ and then draw a second firm based on our initial guess. The distribution of our second firm, $X_1$, is given by\n",
    "$$\n",
    "X_1=PX_0\n",
    "$$\n",
    "where the transition matrix $P$ corresponds to the chance of keeping a firm given in the previous part. \n",
    "\n",
    "After we draw the second firm, we draw a third firm based on our second firm. The distribution of our third firm, $X_2$, is given by \n",
    "$$\n",
    "X_2=PX_1\n",
    "$$\n",
    "By now you probably realize what we are trying to do here: the distributions of the firms that we keep $X_1,X_2,X_3,…$ form a Markov Chain, where draws in different time periods are related to each other in the following way:\n",
    "$$\n",
    "X_{t+1}=PX_t\n",
    "$$\n",
    "As we have learnt in the class on Markov Chains, under certain conditions $X_t$ will converge to a stable vector. \n",
    "\n",
    "But what does the stable vector represent? If you look how we record firms in each time step,\n",
    "acceptance probability is increasing in \n",
    "$$\n",
    "\\frac{P\\left(X \\mid i\\right)P\\left(i\\right)}{P\\left(X \\mid c\\right)P\\left(c\\right)}\n",
    "$$\n",
    "What this means is that for any two given types of firms, we always accept more often the one that is more likely. Furthermore, this difference in acceptance probability is proportional to the relative likelihood of the two types. It is for this reason that that stable vector represents the chances of the firm being good and bad, which is what we are looking for.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Type\n",
    "\n",
    "MCMC can be applied to problem much more complex that the one we have here. As an example, let us modify our code to handle continuous firm type&mdash;type $i\\in[0,1]$ has probability $i$ of having good performance in a given month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Simulation count\n",
    "sim_count = 50000\n",
    "\n",
    "def pxi_pi(p):\n",
    "    #P(x|i)P(i)\n",
    "\n",
    "    \n",
    "def MCMC():\n",
    "    #MCMC\n",
    "\n",
    "\n",
    "#Run MCMC\n",
    "\n",
    "\n",
    "#Histogram\n",
    "n, bins, patches = plt.hist(x_list, 100, density=True)\n",
    "print(\"Most probable type:\",bins[np.argmax(n)])\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note here:\n",
    "- The histogram above shows the *posterior distribution* of types. The better a type can explain the data, the higher will its density be. The most probable type is 0.66, which makes sense since 40 good months out of 60 equals 0.67.\n",
    "- Instead of sampling new firms randomly, we sample firms based on a normal distrbution with the previous accepted type as mean. This very common sampling method is called the <a href=\"https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm\">Metropolis-Hastings algorithm</a>.\n",
    "- This script is significantly slower than the first one due to the fact that we are calling ```binom.pmf()``` in every single time step. We need to do this because firm type is continuous, so it is impossible to pre-calculate and cache the probability mass function ahead of time. We can bring back pre-calculation and caching if we are willing to sacrifice some precision and discretize firm type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation count\n",
    "sim_count = 50000\n",
    "\n",
    "class pxipi:\n",
    "    #P(x|i)P(i)\n",
    "    \n",
    "    def __init__(self):\n",
    "        #Calculate and cache binomial distribution at 0.1 interval\n",
    "        self.pxi_pi = [binom.pmf(40,60,p/100) for p in range(1,101)]\n",
    "    \n",
    "    def get(self,p):\n",
    "        #Return P(x|i)P(i)     \n",
    "        return self.pxi_pi[round(p*100)-1]\n",
    "\n",
    "def MCMC():\n",
    "    #MCMC\n",
    "    pxi_pi = pxipi()\n",
    "    x_list = []\n",
    "    x_current = 0.6\n",
    "    for i in range(sim_count):\n",
    "        x_proposal = max(0,min(1,random.gauss(x_current,0.5)))\n",
    "\n",
    "        if pxi_pi.get(x_proposal)/(pxi_pi.get(x_current) + 0.0001) >= random.random():\n",
    "            x_current = x_proposal\n",
    "\n",
    "        x_list.append(x_current)\n",
    "        \n",
    "    return x_list\n",
    "\n",
    "#Run MCMC\n",
    "x_list = MCMC()\n",
    "\n",
    "#Histogram\n",
    "n, bins, patches = plt.hist(x_list, 100, density=True)\n",
    "print(\"Most probable type:\",bins[np.argmax(n)])\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "If you are interested in knowing more about MCMC, I highly recommend Thomas Wiechki's <a href=\"https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/\">MCMC sampling for dummies</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
