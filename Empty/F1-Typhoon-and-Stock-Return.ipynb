{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typhoon and Stock Return\n",
    "\n",
    "In this tutorial, we will investigate whether the stock market performs abnormally after a strong typhoon. We will make extensive use of the data-handling package ```pandas```, the statistical functions of ```scipy``` and the statistics package ```statsmodel```.\n",
    "\n",
    "## A. Data Cleaning\n",
    "\n",
    "### A1. Typhoon data\n",
    "\n",
    "The typhoon data is obtained from the Hong Kong Observatory. \n",
    "Each row contains data for a particular signal. Since typhoons often go through\n",
    "several signals, there are multiple rows for each typhoon.\n",
    "\n",
    "We will first do some preprocessing:\n",
    "- Since we are only interested in the effect of strong typhoons, we will only keep typhoons that have a maximum signal at or above No. 8. \n",
    "- We will also keep record of the date each typhoon went below Signal No. 8.\n",
    "\n",
    "A few notable pandas techniques that we will be using:\n",
    "- To **select rows** out of a DataFrame whenever a certain column satisfying an inequality, use\n",
    "```python\n",
    "DataFrame[DataFrame['column_name'] >= value]\n",
    "```\n",
    "More generally, you can select rows by supplying a list of True/False values.\n",
    "\n",
    "\n",
    "- To convert a column to pandas **datatime** format, use ```pd.to_datetime()```.\n",
    "  You can then extract individual date components by ```.dt.year```, ```.dt.month``` etc.\n",
    "  For example, to extract year out of a column called *date*, you can write:\n",
    "  ```python\n",
    "  DataFrame('date') = pd.to_datetime(DataFrame('date'))\n",
    "  DataFrame('year') = DataFrame('date').dt.year \n",
    "  ```\n",
    "\n",
    "\n",
    "- There are two ways to calculate the summary statistic of column B **grouped by** values of column A:\n",
    "    - To collapse to one row per group, use:\n",
    "        ```python\n",
    "        DataFrame.groupby('column_A')['column_B'].ops()\n",
    "        ```\n",
    "        where `opts()` can be operations such as `mean()`, `max()`, etc. \n",
    "        Note that this method returns a pandas Series instead of a DataFrame. \n",
    "        To get a DataFrame, append `.to_frame()` at the end.\n",
    "    - If you want to maintain the original number of rows, use:\n",
    "        ```python\n",
    "        DataFrame.groupby('column_A')['column_B'].transform('ops')\n",
    "        ```\n",
    "\n",
    "- To **drop duplicates**, use\n",
    "```python\n",
    "DataFrame.drop_duplicates(subset,keep)\n",
    "```\n",
    "    - `subset`: by default pandas consider two rows to be duplicates only \n",
    "    if they are identical for all columns. You can specify a narrower set of columns here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import data and keep only signal 8 or above\n",
    "typhoon_data = pd.read_excel(\"../Data/typhoon_hk.xlsx\")\n",
    "\n",
    "\n",
    "# Convert date to pandas datatime format and extract year\n",
    "\n",
    "\n",
    "# Find the highest signal for each typhoon and store it in 'Signal_max'\n",
    "\n",
    "\n",
    "# Keep only the last date for each typhoon\n",
    "\n",
    "\n",
    "# Keep only three variables\n",
    "\n",
    "\n",
    "# Show the data\n",
    "typhoon_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Stock data\n",
    "\n",
    "For stock data, we will calculate the return from the previous trading day.\n",
    "\n",
    "The most notable pandas technique we use here is ```.shift(x)```. \n",
    "This method shifts all rows down by *x* rows.\n",
    "The nice thing about this technique is that you can totally do things\n",
    "like \n",
    "```python\n",
    "stock_data[\"Price\"]/stock_data.shift(1)[\"Price\"] - 1\n",
    "```\n",
    "which gives you all daily return in one single line.\n",
    "\n",
    "Other notable techniques:\n",
    "- **Drop rows with missing values**\n",
    "```python\n",
    "DataFrame.dropna()\n",
    "```\n",
    "- **Convert column(s) to numeric format**\n",
    "```python\n",
    "pd.to_numeric(DataFrame[['column_name']])\n",
    "```\n",
    "Specify `errors='coerce'` to force convert. Any values that is not numeric\n",
    "will be converted to `NaN`.\n",
    "\n",
    "\n",
    "- **Fill in missing dates**: first change the DataFrame's index to a date variable:\n",
    "```python\n",
    "DataFrame.index = pd.DatetimeIndex(DataFrame['date_column'])\n",
    "```\n",
    "Then\n",
    "```python\n",
    "DataFrame.asfreq(freq)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stock data and keep only two variables\n",
    "stock_data = pd.read_csv(\"../Data/hsi.csv\")\n",
    "stock_data = stock_data[[\"Date\",\"Adj Close\"]]\n",
    "\n",
    "# Convert date to pandas datetime format\n",
    "\n",
    "\n",
    "# Adj Close is NaN on some dates. \n",
    "# Force convert everything to numeric and drop missing.\n",
    "\n",
    "\n",
    "# Calculate return since the previous trading day\n",
    "\n",
    "\n",
    "# 90-day future return\n",
    "\n",
    "\n",
    "# Use date as the index of the dataframe and fill in missing dates\n",
    "\n",
    "\n",
    "# Show the data\n",
    "stock_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Merge stock and typhoon data\n",
    "\n",
    "We can now merge the stock and typhoon data. To **merge** two DataFrames A and B, use\n",
    "```python\n",
    "DataFrame_A.merge(DataFrame_B, options)\n",
    "```\n",
    "common options include:\n",
    "- `how`: whether the merge keeps all samples from the left DataFrame (A), \n",
    "the right DataFrame (B), a union of the two or intersection. \n",
    "Default is intersection, which means only samples that appear on both DataFrames\n",
    "will be kept.\n",
    "- `left_on` and `right_on`: the name of the columns used to match the two DataFrames.\n",
    "- `left_index` and `right index`: use the DataFrame index instead of a column for the match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless the typhoon's signal went below No. 8 before market opens, no stock data will be available for the given `end_date`. In this case we use the return from the next trading day.\n",
    "\n",
    "First we extract the list of such typhoons. We can do that by using the ```.isnull()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we merge in stock information from the next day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If return is still missing after this step, it must be the case that at least two days have passed since Signal No. 8 was lowered. We will ignore such instances.\n",
    "\n",
    "To append one DataFrame at the bottom of another, use ```.append()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Statistical Analysis\n",
    "\n",
    "Finally we can perform some statistical analysis. We will start with comparing the daily return on the first trading day after a typhoon versus all other days.\n",
    "\n",
    "### B1. Statistical Tests\n",
    "\n",
    "```scipy.stats``` contains many of the common tests. Noteable ones include:\n",
    "- **T-test**: ```ttest_ind(A,B)```.\n",
    "- **Median Test**: ```median_test(A,B)```. \n",
    "- **Mann-Whitney rank test**: ```mannwhitneyu(A,B)```. A non-parametric test on whether A and B have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Stock data without typhoon. '~' means 'not'.\n",
    "\n",
    "\n",
    "# Mean daily returns\n",
    "\n",
    "\n",
    "# T-test\n",
    "\n",
    "\n",
    "# Mood's median test\n",
    "\n",
    "\n",
    "# Mann-Whitney test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out the stock market on average performs better right after a typhoon! The difference is not statistically significant though.\n",
    "\n",
    "### B2. Regression\n",
    "\n",
    "We can also run a regression. Note that running a regression with a single dummy variable is identical to running a T-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal max = 0 if no typhoon\n",
    "data_wo_typhoon['Signal_max'] = 0\n",
    "data_whole = data_w_typhoon.append(data_wo_typhoon)\n",
    "\n",
    "# Convert Signal_max to a dummy variable called 'typhoon'\n",
    "data_whole[\"typhoon\"] = 0\n",
    "data_whole.loc[data_whole['Signal_max']>=8,'typhoon'] = 1\n",
    "\n",
    "# scipy OLS\n",
    "stats.linregress(data_whole['typhoon'],data_whole['daily_return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer output that is more in line with what a statistical package like Stata would give you, use ```statsmodels``` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statsmodel OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# statsmodel does not add the constant by default, so add manually\n",
    "results = sm.OLS(data_whole['daily_return'],\n",
    "                 sm.add_constant(data_whole['typhoon'])).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As as a statistical package, ```statsmodels``` have many of the common procedures built in. For example, we can correct for serial correlation by computing the Newey-West Standard Errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newey-West Standard Errors. Note that we are using the results\n",
    "# from the previous regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another idea: what about buying HSI right after a typhoon? Let us compare the mean return of buying right after a typhoon versus that of other days. We will assume a fixed 90-day holding period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want Newey-West standard errors to begin with, this is how:\n",
    "results = sm.OLS(data_whole['90d_return'],\n",
    "              sm.add_constant(data_whole['typhoon'])\n",
    "             ).fit(cov_type='HAC',cov_kwds={'maxlags':5})\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buying after typhoon gives us on average a 2.6% higher return over 3 months! To bad it is not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. That's It? No Significant Result?\n",
    "\n",
    "Let us plot the distribution of returns for days with typhoon and without:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data_whole.hist(column='90d_return',by='typhoon')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does look like return is higher after a typhoon. Thinking about it, a Signal 8 typhoon is often quite predestrian---people actually go out for breakfast and movies. What if we focus only on the strongest typhoons? I leave this as an exercise for you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
