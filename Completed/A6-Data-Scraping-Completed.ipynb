{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping\n",
    "Version: 2025-10-3\n",
    "\n",
    "In this exercise, we will scrape data from Hong Kong Jockey Club's race result page: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST\n",
    "\n",
    "Libraries needed:\n",
    "- For downloading files, `urllib.request`: https://docs.python.org/3.8/library/urllib.request.html\n",
    "- For static webpage, `requests`: http://docs.python-requests.org/en/master/ \n",
    "- For dynamic webpage, `selenium`: https://selenium-python.readthedocs.io/\n",
    "- For parsing the webpage, `BeautifulSoup`: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- Regular expression: https://docs.python.org/3.6/library/re.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Downloading Files\n",
    "\n",
    "The syntax for `urlretrieve` is:\n",
    "```python\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "```\n",
    "This saves the file fetched from `url` as `filename`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('handout.pdf', <http.client.HTTPMessage at 0x7fb120103290>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download a file using urlretrieve\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://scrp.econ.cuhk.edu.hk/workshops/stata-workshop/stata-workshop-handout.pdf\", \"handout.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fetching the Webpage\n",
    "\n",
    "To scrape a website, We first use ```requests``` or ```selenium``` to access a page, which we then pass to ```BeautifulSoup``` to parse into a searchable structure. Regular expression allows us to find specific part of the structure by keyword match.\n",
    "\n",
    "We will begin by fetching the webpage. Because HKJC has switched to using a dynamic page with Javascript and AJAX, we will use `selenium`, which loads the webpage through an actual browser.\n",
    "\n",
    "Selenium needs an interface, called *WebDriver*, to control the browser. We will use the `webdriver_manager` library to locate the correct driver for our choice of browser.\n",
    "\n",
    "After loading the webpage, we can fetch the webpage's source with `driver.page_source`.\n",
    "\n",
    "We should close the browser with `driver.quit()` once we have the page source to free resources taken by the browser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "# Set up selenium to use Firefox\n",
    "options = Options()\n",
    "options.add_argument('-headless') #No need to open a browser window\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "# Fetch the page\n",
    "driver.get('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST')\n",
    "\n",
    "# Make a copy of the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# we can close the browser and clear out Selenium\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use Chrome instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Set up selenium to use Chrome\n",
    "options = Options()\n",
    "options.add_argument('--headless=new') #No need to open a browser window\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Fetch the page\n",
    "driver.get('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST')\n",
    "\n",
    "# Make a copy of the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Once the data is passed to Beautiful Soup \n",
    "# we can close the browser and clear out Selenium\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the page static then we can use `requests`, which does not require a browser to work. We can fetch the webpage's source with `page.text`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works with static content\n",
    "import requests\n",
    "\n",
    "# URL of data\n",
    "url = \"http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST\"\n",
    "\n",
    "# Access the page\n",
    "page = requests.get(url)\n",
    "\n",
    "# Make a copy of the page source\n",
    "page_source = page.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we fetch the website, we will pass it to `BeautifulSoup` for parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load the page into BeautifulSoup\n",
    "# Change 'driver.page_source' to 'page.content' when using requests\n",
    "soup = BeautifulSoup(page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Getting a Table\n",
    "\n",
    "If the data you need is in a table, the easiest way to scrape it is to:\n",
    "1. Find the table based on certain characteristics, either by a name, an ID or class.\n",
    "2. Loop through the rows in the table.\n",
    "3. Loop through each cell in a row and extract its content.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pla.',\n",
       "  'Horse No.',\n",
       "  'Horse',\n",
       "  'Jockey',\n",
       "  'Trainer',\n",
       "  'Act. Wt.',\n",
       "  'Declar. Horse Wt.',\n",
       "  'Dr.',\n",
       "  'LBW',\n",
       "  'RunningPosition',\n",
       "  'Finish Time',\n",
       "  'Win Odds'],\n",
       " ['1',\n",
       "  '10',\n",
       "  'JOLLY JOLLY(T087)',\n",
       "  'K Teetan',\n",
       "  \"P O'Sullivan\",\n",
       "  '114',\n",
       "  '1214',\n",
       "  '13',\n",
       "  '-',\n",
       "  '1111',\n",
       "  '1:22.05',\n",
       "  '2.6']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [] \n",
    "\n",
    "# Find the table\n",
    "table = soup.find(\"table\", class_=\"f_tac\")\n",
    "\n",
    "# Loop through all rows\n",
    "for tr in table.find_all(\"tr\"):\n",
    "    cells = tr.find_all(\"td\")\n",
    "    # Loop through all cells in a row\n",
    "    row = [cell.get_text(strip=True) for cell in cells]\n",
    "    data.append(row)\n",
    "\n",
    "# Show content\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Getting a Single Column of Data\n",
    "\n",
    "If the data is not nicely formatted as an HTML table, we can locate it directly.\n",
    "\n",
    "Let's begin with fetching the names of the horses. We note that each horse's name is enclosed in a HTML ```<a>``` tag, with the term *HorseId* contained in its hypertext reference.\n",
    "\n",
    "<img src=\"../Images/webscraping-2020/HorseId.png\" style=\"border: 1px solid grey; width: 750px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOLLY JOLLY\n",
      "PEOPLE'S KNIGHT\n",
      "RUN FORREST\n",
      "MODERN TSAR\n",
      "MAGNETISM\n",
      "ENORMOUS HONOUR\n",
      "HAPPY JOURNEY\n",
      "WINGOLD\n",
      "OVETT\n",
      "PAKISTAN BABY\n",
      "SUPER FLUKE\n",
      "JUN GONG\n",
      "LAUGH OUT LOUD\n",
      "TEN SPEED\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Find all tags with href containing \"horseno\"\n",
    "#horses is a list of matched tags\n",
    "horses = soup.find_all(href=re.compile(\"HorseId\"))\n",
    "\n",
    "# Print the result\n",
    "for horse in horses:\n",
    "    print(horse.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for jockeys, noting that each jockey name is enclosed in a ```<a>``` tag with hypertext reference containing the term *JockeyProfile.aspx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Teetan\n",
      "J Moreira\n",
      "M L Yeung\n",
      "C Y Ho\n"
     ]
    }
   ],
   "source": [
    "# Find all tags with href containing \"JockeyProfile.aspx\" \n",
    "jockeys = soup.find_all(href=re.compile(\"JockeyProfile.aspx\"))\n",
    "\n",
    "# Print the result\n",
    "for jockey in jockeys:\n",
    "    print(jockey.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also match by the class of the ```<td>``` tag one layer up. This would return horse names, jockey names and trainer names.\n",
    "\n",
    "<img src=\"../Images/webscraping-2020/HorseClass.png\" style=\"border: 1px solid grey; width: 750px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOLLY JOLLY (T087)\n",
      "K Teetan\n",
      "P O'Sullivan\n",
      "PEOPLE'S KNIGHT (T305)\n",
      "T Berry\n",
      "J Moore\n",
      "RUN FORREST (T176)\n",
      "J Moreira\n",
      "C S Shum\n",
      "MODERN TSAR (S167)\n",
      "B Prebble\n",
      "W Y So\n",
      "MAGNETISM (V114)\n",
      "G Lerena\n",
      "D E Ferraris\n",
      "ENORMOUS HONOUR (T236)\n",
      "N Rawiller\n",
      "Y S Tsui\n",
      "HAPPY JOURNEY (S299)\n",
      "H W Lai\n",
      "S Woods\n",
      "WINGOLD (T202)\n",
      "M L Yeung\n",
      "A Lee\n",
      "OVETT (P351)\n",
      "H N Wong\n",
      "A T Millard\n",
      "PAKISTAN BABY (S442)\n",
      "D Whyte\n",
      "A S Cruz\n",
      "SUPER FLUKE (T382)\n",
      "M Demuro\n",
      "D Cruz\n",
      "JUN GONG (N325)\n",
      "C Y Ho\n",
      "C H Yip\n",
      "LAUGH OUT LOUD (P297)\n",
      "G Mosse\n",
      "K L Man\n",
      "TEN SPEED (T239)\n",
      "Y T Cheng\n",
      "C W Chang\n"
     ]
    }
   ],
   "source": [
    "data = soup.find_all(\"td\",class_=\"f_fs13 f_tal\")\n",
    "\n",
    "for d in data:\n",
    "    print(d.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Fetching Adjacent Fields\n",
    "Let's now try fetching the jockeys' and trainers' names, having first located the horse names.\n",
    "\n",
    "<img src=\"../Images/webscraping-2020/HorseId_siblings.png\" style=\"border: 1px solid grey; width: 750px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOLLY JOLLY          K Teetan        P O'Sullivan\n",
      "PEOPLE'S KNIGHT      T Berry         J Moore\n",
      "RUN FORREST          J Moreira       C S Shum\n",
      "MODERN TSAR          B Prebble       W Y So\n",
      "MAGNETISM            G Lerena        D E Ferraris\n",
      "ENORMOUS HONOUR      N Rawiller      Y S Tsui\n",
      "HAPPY JOURNEY        H W Lai         S Woods\n",
      "WINGOLD              M L Yeung       A Lee\n",
      "OVETT                H N Wong        A T Millard\n",
      "PAKISTAN BABY        D Whyte         A S Cruz\n",
      "SUPER FLUKE          M Demuro        D Cruz\n",
      "JUN GONG             C Y Ho          C H Yip\n",
      "LAUGH OUT LOUD       G Mosse         K L Man\n",
      "TEN SPEED            Y T Cheng       C W Chang\n"
     ]
    }
   ],
   "source": [
    "# Loop through each horse and find the jockey and trainer along the way\n",
    "from bs4 import NavigableString\n",
    "\n",
    "for horse in horses:\n",
    "    \n",
    "    # jockey is supposed to be horse.parent.next_sibling\n",
    "    jockey = horse.parent.next_sibling\n",
    "       \n",
    "    # But there are whitespace between tags, which BeautifulSoup picks \n",
    "    # up as 'NavigableString'. We use a while loop to keep moving when \n",
    "    # we encounter such cases\n",
    "    while isinstance(jockey, NavigableString):\n",
    "            jockey = jockey.next_sibling\n",
    "            \n",
    "    # Now do the same to find trainer            \n",
    "    trainer = jockey.next_sibling\n",
    "    while isinstance(trainer, NavigableString):\n",
    "            trainer = trainer.next_sibling\n",
    "    \n",
    "    # Print what we find\n",
    "    print(horse.text.strip().ljust(20),\n",
    "          jockey.text.strip().ljust(15),\n",
    "          trainer.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are going to need to deal with whitespace very often, let us first write a function that runs the while loop for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import NavigableString\n",
    "\n",
    "def get_sibling(tag,previous=False):\n",
    "    if previous:\n",
    "        sibling = tag.previous_sibling\n",
    "        while isinstance(sibling, NavigableString):\n",
    "            sibling = sibling.previous_sibling\n",
    "    else:\n",
    "        sibling = tag.next_sibling\n",
    "        while isinstance(sibling, NavigableString):\n",
    "            sibling = sibling.next_sibling        \n",
    "    return sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop through all horses and fetch other fields relative to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOLLY JOLLY          K Teetan        P O'Sullivan    114             1214\n",
      "PEOPLE'S KNIGHT      T Berry         J Moore         119             1163\n",
      "RUN FORREST          J Moreira       C S Shum        115             1135\n",
      "MODERN TSAR          B Prebble       W Y So          123             1101\n",
      "MAGNETISM            G Lerena        D E Ferraris    125             1130\n",
      "ENORMOUS HONOUR      N Rawiller      Y S Tsui        131             1127\n",
      "HAPPY JOURNEY        H W Lai         S Woods         114             1040\n",
      "WINGOLD              M L Yeung       A Lee           111             1154\n",
      "OVETT                H N Wong        A T Millard     105             1153\n",
      "PAKISTAN BABY        D Whyte         A S Cruz        121             1023\n",
      "SUPER FLUKE          M Demuro        D Cruz          120             1109\n",
      "JUN GONG             C Y Ho          C H Yip         115             1147\n",
      "LAUGH OUT LOUD       G Mosse         K L Man         126             1127\n",
      "TEN SPEED            Y T Cheng       C W Chang       116             1033\n"
     ]
    }
   ],
   "source": [
    "# Use jockey instead\n",
    "for horse in horses:\n",
    "    jockey = get_sibling(horse.parent)\n",
    "    trainer = get_sibling(jockey)\n",
    "    actual_weight = get_sibling(trainer)\n",
    "    declare_weight = get_sibling(actual_weight)\n",
    "\n",
    "    print(horse.text.strip().ljust(20),\n",
    "          jockey.text.strip().ljust(15),\n",
    "          trainer.text.strip().ljust(15),\n",
    "          actual_weight.text.strip().ljust(15),\n",
    "          declare_weight.text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, we can use a while loop to fetch adjacent fields until \n",
    "there is nothing left to fetch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['JOLLY JOLLY',\n",
       "  'K Teetan',\n",
       "  \"P O'Sullivan\",\n",
       "  '114',\n",
       "  '1214',\n",
       "  '13',\n",
       "  '-',\n",
       "  '1                  \\r1                  \\r1                  \\r1',\n",
       "  '1:22.05',\n",
       "  '2.6'],\n",
       " [\"PEOPLE'S KNIGHT\",\n",
       "  'T Berry',\n",
       "  'J Moore',\n",
       "  '119',\n",
       "  '1163',\n",
       "  '8',\n",
       "  '2',\n",
       "  '2                  \\r4                  \\r2                  \\r2',\n",
       "  '1:22.39',\n",
       "  '5.7']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'data' is the whole table, 'row' is a single row\n",
    "data = []\n",
    "\n",
    "# Loop through horses\n",
    "for horse in horses:\n",
    "\n",
    "    # Get the horse name\n",
    "    row = [horse.text.strip()]\n",
    "    \n",
    "    # This while loop fetch all remaining fields in a row\n",
    "    a = get_sibling(horse.parent)\n",
    "    while a != None:\n",
    "        row.append(a.text\n",
    "                      .strip()\n",
    "                      # The last two lines are for running positions\n",
    "                      .replace('\\n','') \n",
    "                      .replace(' '*20,' ') \n",
    "                     )\n",
    "        a = get_sibling(a)\n",
    "    \n",
    "    # Append each row to the output list\n",
    "    data.append(row)\n",
    "\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Multiple Pages\n",
    "\n",
    "Most of the time we need more than one page. We can go through pages with for loop(s).\n",
    "\n",
    "Before we go there, let's write a helper function that returns the content we want from each page in a list. Because we are going to load multiple pages consecutively, we need a way to ensure each page is loaded before we move on to the next. For this we need `WebDriverWait`, which allows Selenium to wait for certain conditions to be true before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "\n",
    "def scrape_horses(url):\n",
    "    # Function to access a page and save all horses into a list\n",
    "\n",
    "    # Fetch the page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Is there anything?\n",
    "    if driver.page_source.find(\"No information.\") != -1:\n",
    "        return []\n",
    "    \n",
    "    # Wait 30 secs so that the dynamic content has time to load.\n",
    "    # Proceed to next date if page doesn't load.\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"f_fs13\")))\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    # Load the page into BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Here we can use whatever method that fetches what we need\n",
    "    data = [] \n",
    "    table = soup.find(\"table\", class_=\"f_tac\")\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        cells = tr.find_all(\"td\")\n",
    "        # Loop through all cells in a row\n",
    "        row = [cell.get_text(strip=True) for cell in cells]\n",
    "        data.append(row)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first try the function on one single page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pla.',\n",
       "  'Horse No.',\n",
       "  'Horse',\n",
       "  'Jockey',\n",
       "  'Trainer',\n",
       "  'Act. Wt.',\n",
       "  'Declar. Horse Wt.',\n",
       "  'Dr.',\n",
       "  'LBW',\n",
       "  'RunningPosition',\n",
       "  'Finish Time',\n",
       "  'Win Odds'],\n",
       " ['1',\n",
       "  '10',\n",
       "  'JOLLY JOLLY(T087)',\n",
       "  'K Teetan',\n",
       "  \"P O'Sullivan\",\n",
       "  '114',\n",
       "  '1214',\n",
       "  '13',\n",
       "  '-',\n",
       "  '1111',\n",
       "  '1:22.05',\n",
       "  '2.6']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = Options()\n",
    "options.add_argument('-headless') #No need to open a browser window\n",
    "driver = webdriver.Firefox(options=options)\n",
    "output = scrape_horses('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST')\n",
    "driver.quit()\n",
    "output[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the loops. Note that month and day are always in two digits. \n",
    "\n",
    "String formatting: https://docs.python.org/3.4/library/string.html#format-string-syntax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170101\n",
      "[['Pla.', 'Horse No.', 'Horse', 'Jockey', 'Trainer', 'Act. Wt.', 'Declar. Horse Wt.', 'Dr.', 'LBW', 'RunningPosition', 'Finish Time', 'Win Odds'], ['1', '2', 'ROCK THE TREE(P272)', 'B Prebble', 'D E Ferraris', '133', '1056', '11', '-', '121211121', '2:03.16', '9.7'], ['2', '9', 'HIGH SPEED METRO(P293)', 'K C Leung', 'L Ho', '119', '1169', '12', '3/4', '11101042', '2:03.31', '10'], ['3', '13', 'WIN CHANCE(P415)', 'M L Yeung', 'A Lee', '112', '1026', '2', '4', '77723', '2:03.82', '17'], ['4', '11', 'LOYAL CRAFTSMAN(S354)', 'S Clipperton', 'D E Ferraris', '120', '1080', '13', '4-1/2', '13131394', '2:03.88', '8.3'], ['5', '1', 'CHOICE EXCHEQUER(P088)', 'A Badel', 'C H Yip', '133', '1209', '3', '5-1/2', '11115', '2:04.03', '15'], ['6', '4', 'SWEET BEAN(S205)', 'N Callan', 'C Fownes', '128', '1031', '7', '5-3/4', '888106', '2:04.10', '22'], ['7', '3', 'TELEPHATIA(P405)', 'Z Purton', 'A Lee', '130', '1077', '8', '6', '109977', '2:04.13', '7.9'], ['8', '5', 'KERKENI(T053)', 'O Doleuze', 'R Gibson', '127', '1053', '5', '6-1/4', '91112118', '2:04.16', '12'], ['9', '8', 'GLAMOROUS RYDER(S007)', 'S De Sousa', 'D E Ferraris', '123', '1098', '6', '8', '66669', '2:04.45', '18'], ['10', '12', 'VIVACIOUS WINNER(V061)', 'K K Chiong', 'D Cruz', '109', '1193', '4', '9-3/4', '555810', '2:04.73', '14'], ['11', '7', 'MY FOLKS(T323)', 'O Murphy', 'C W Chang', '124', '1174', '1', '15-1/2', '343511', '2:05.66', '3.7'], ['12', '10', 'MAGIC STAR(T266)', 'T H So', \"P O'Sullivan\", '119', '1150', '9', '18-1/2', '222312', '2:06.12', '92'], ['13', '6', 'FRANCE VALOUR(S408)', 'J Moreira', 'T P Yung', '126', '1148', '10', '72-1/2', '4341313', '2:14.75', '8.6']]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170102\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170103\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170104\n",
      "[['Pla.', 'Horse No.', 'Horse', 'Jockey', 'Trainer', 'Act. Wt.', 'Declar. Horse Wt.', 'Dr.', 'LBW', 'RunningPosition', 'Finish Time', 'Win Odds'], ['1', '3', 'INVISIBLE(T418)', 'O Doleuze', 'C Fownes', '132', '1128', '5', '-', '561', '1:10.94', '9.2'], ['2', '2', 'FOREVER FUN(S130)', 'S De Sousa', 'K L Man', '132', '1032', '12', 'N', '222', '1:10.98', '22'], ['3', '5', 'SIR JOHN(P344)', 'O Murphy', 'W Y So', '130', '1161', '1', '1-3/4', '343', '1:11.23', '13'], ['4', '7', 'TREASURE AND GOLD(V027)', 'J Moreira', 'C H Yip', '126', '1143', '9', '2-1/4', '654', '1:11.32', '3.7'], ['5', '6', 'OPTIMISM(S150)', 'N Callan', 'D E Ferraris', '126', '1075', '2', '2-1/2', '995', '1:11.34', '7.5'], ['6', '1', 'RICHCITY FORTUNE(V088)', 'S Clipperton', 'J Moore', '133', '1145', '8', '2-1/2', '436', '1:11.34', '5'], ['7', '11', 'INTELLECTUAL GLIDE(S124)', 'M L Yeung', 'A Lee', '111', '1014', '3', '3-1/4', '12127', '1:11.47', '11'], ['8', '9', 'TELECOM BOOM(V144)', 'Z Purton', 'Y S Tsui', '123', '1107', '6', '3-1/4', '11118', '1:11.48', '7.8'], ['9', '4', 'GIDDY GIDDY(S367)', 'B Prebble', 'J Size', '130', '1130', '10', '3-1/2', '119', '1:11.52', '8.4'], ['10', '10', 'PERFECT SMART(S413)', 'M Chadwick', 'C W Chang', '121', '1074', '4', '5-3/4', '7710', '1:11.87', '42'], ['11', '8', 'CHANS DELIGHT(P420)', 'K K Chiong', 'D Cruz', '118', '1095', '11', '7', '8811', '1:12.06', '58'], ['12', '12', 'ABLE TALENT(S446)', 'K C Ng', 'T K Ng', '108', '1042', '7', '7', '101012', '1:12.07', '101']]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170105\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170106\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170107\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170108\n",
      "[['Pla.', 'Horse No.', 'Horse', 'Jockey', 'Trainer', 'Act. Wt.', 'Declar. Horse Wt.', 'Dr.', 'LBW', 'RunningPosition', 'Finish Time', 'Win Odds'], ['1', '1', 'BEST EFFORT(T220)', 'M L Yeung', 'A Lee', '131', '1018', '5', '-', '4321', '1:35.38', '7.5'], ['2', '2', 'CASH COURIER(S417)', 'S De Sousa', 'K L Man', '133', '1215', '9', 'N', '9882', '1:35.44', '6.9'], ['3', '7', 'GORGEOUS AGAIN(V326)', 'J Moreira', 'C S Shum', '127', '1066', '12', '3/4', '1010103', '1:35.51', '4.4'], ['4', '11', 'LUCKY PLACE(T004)', 'O Doleuze', 'C W Chang', '120', '1064', '8', '1-1/4', '6664', '1:35.60', '7.7'], ['5', '4', 'DANEWIN EXPRESS(S234)', 'Z Purton', 'Y S Tsui', '130', '1146', '14', '2-3/4', '1414145', '1:35.82', '6.5'], ['6', '13', 'DRAGON GLORY(P130)', 'A Badel', 'C W Chang', '113', '1110', '11', '2-3/4', '7776', '1:35.83', '109'], ['7', '8', 'SWEET BEAN(S205)', 'O Murphy', 'C Fownes', '127', '1021', '2', '4', '1111137', '1:36.01', '34'], ['8', '10', 'MEDIC SWORDSMAN(P168)', 'H T Mo', 'D Cruz', '109', '1177', '13', '5-1/2', '1312118', '1:36.25', '95'], ['9', '12', 'PERFECT TIMING(T019)', 'M Chadwick', 'T P Yung', '113', '1091', '10', '5-1/2', '1213129', '1:36.26', '16'], ['10', '9', 'DASHING FORTUNE(P046)', 'N Callan', 'D E Ferraris', '124', '1149', '1', '6-1/4', '54410', '1:36.39', '7.6'], ['11', '6', 'FANTASTICLIFE(S320)', 'K Teetan', 'C Fownes', '127', '1105', '3', '8-3/4', '89911', '1:36.77', '12'], ['12', '5', 'POWER DRAGON(V129)', 'K K Chiong', 'C H Yip', '123', '1151', '4', '12-3/4', '11112', '1:37.44', '16'], ['13', '3', 'DASHING SUPER(N348)', 'C Y Ho', 'Y S Tsui', '130', '1172', '6', '14-1/4', '35513', '1:37.66', '72'], ['14', '14', 'FRESH AND FRESH(P407)', 'K C Ng', 'L Ho', '108', '1079', '7', '15-1/2', '22314', '1:37.85', '31']]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170109\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170110\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170111\n",
      "[['Pla.', 'Horse No.', 'Horse', 'Jockey', 'Trainer', 'Act. Wt.', 'Declar. Horse Wt.', 'Dr.', 'LBW', 'RunningPosition', 'Finish Time', 'Win Odds'], ['1', '4', 'GLORY STAR(T336)', 'J Moreira', 'C S Shum', '128', '1116', '4', '-', '6651', '1:40.57', '2.4'], ['2', '12', 'GOLDEN PARTNERS(S286)', 'C Schofield', 'A T Millard', '118', '1101', '6', '1-1/4', '9992', '1:40.76', '10'], ['3', '1', 'SUPER SWEET ORANGE(V058)', 'N Callan', 'D E Ferraris', '130', '1243', '7', '1-1/4', '1113', '1:40.77', '5'], ['4', '11', 'LAUGHING LORD(T071)', 'O Doleuze', 'C W Chang', '122', '1095', '1', '3', '3334', '1:41.05', '12'], ['5', '6', 'PRECISIONCRAFTSMAN(V036)', 'M L Yeung', 'T P Yung', '126', '1066', '2', '3', '7785', '1:41.06', '20'], ['6', '5', 'MALAYAN PEARL(N416)', 'S Clipperton', 'D Cruz', '128', '1173', '3', '3-1/4', '2226', '1:41.11', '23'], ['7', '2', 'WEALTHY FORTUNE(P324)', 'S De Sousa', 'K L Man', '129', '1026', '8', '3-1/2', '1010107', '1:41.12', '17'], ['8', '8', 'YOURTHEWONFORME(T258)', 'A Badel', 'T K Ng', '125', '1129', '9', '3-3/4', '8878', '1:41.17', '18'], ['9', '10', 'MY BLESSING(V164)', 'Z Purton', 'C H Yip', '123', '1068', '10', '4', '1111119', '1:41.20', '10'], ['10', '7', 'BEST JADE TRIUMPH(P070)', 'B Prebble', 'A Lee', '127', '1022', '12', '5-3/4', '12121210', '1:41.47', '22'], ['11', '9', 'LUCKY BALL(T130)', 'O Murphy', 'D J Hall', '124', '1055', '5', '10', '45611', '1:42.15', '21'], ['12', '3', 'DOUBLE POINT(S246)', 'K Teetan', 'C Fownes', '128', '1040', '11', '10', '54412', '1:42.17', '30']]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170112\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170113\n",
      "[]\n",
      "http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170114\n",
      "[['Pla.', 'Horse No.', 'Horse', 'Jockey', 'Trainer', 'Act. Wt.', 'Declar. Horse Wt.', 'Dr.', 'LBW', 'RunningPosition', 'Finish Time', 'Win Odds'], ['1', '2', 'RICHCITY FORTUNE(V088)', 'B Prebble', 'J Moore', '132', '1142', '9', '-', '111', '1:10.25', '3.4'], ['2', '12', \"BERNARD'S CHOICE(N156)\", 'K Teetan', 'T K Ng', '113', '1065', '5', '2-3/4', '1082', '1:10.68', '20'], ['3', '9', 'TELECOM BOOM(V144)', 'C Y Ho', 'Y S Tsui', '120', '1102', '1', '4-1/4', '663', '1:10.91', '14'], ['4', '11', 'GREAT SPEED(S251)', 'S De Sousa', 'L Ho', '116', '1089', '3', '4-1/4', '334', '1:10.93', '8.1'], ['5', '3', \"EVERYONE'S CHOICE(P208)\", 'N Callan', 'K L Man', '131', '1160', '7', '4-3/4', '225', '1:11.02', '10'], ['6', '5', 'LEAN JOURNEY(S389)', 'O Doleuze', 'C H Yip', '127', '1118', '11', '6-3/4', '876', '1:11.33', '9.9'], ['7', '10', 'STARRY STARLIES(T429)', 'J Moreira', \"P O'Sullivan\", '117', '1169', '12', '7-1/2', '11117', '1:11.45', '4'], ['8', '8', 'SILVER GATSBY(T161)', 'O Murphy', 'W Y So', '123', '1146', '8', '8-3/4', '548', '1:11.67', '13'], ['9', '4', 'MANHATTAN STRIKER(V141)', 'C Schofield', 'C Fownes', '128', '1111', '4', '10-1/4', '459', '1:11.90', '15'], ['10', '1', 'EMPIRE OF MONGOLIA(V317)', 'H T Mo', 'C S Shum', '123', '1050', '10', '11-1/4', '71010', '1:12.07', '46'], ['11', '7', 'THUNDER DASH(T133)', 'A Badel', 'D Cruz', '126', '1062', '2', '11-3/4', '9911', '1:12.14', '13'], ['WV-A', '6', 'STRIKING STAR(V015)', 'M L Yeung', 'A Lee', '125', '---', '---', '---', '---', '---', '---']]\n"
     ]
    }
   ],
   "source": [
    "#URL of data\n",
    "url_front = \"http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/\"\n",
    "\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "#Write a loop to go through year, month and day\n",
    "#Note that month and day is always 2 digit\n",
    "#Call scrape_horses() in each iteration\n",
    "for year in range(2017,2018):\n",
    "    for month in range(1,2):\n",
    "        for day in range(1,15):\n",
    "            \n",
    "            #Convert month and day to 2-digit representation\n",
    "            month_2d = '{:02d}'.format(month)\n",
    "            day_2d = '{:02d}'.format(day)\n",
    "            \n",
    "            url = url_front + str(year) + month_2d + day_2d\n",
    "            \n",
    "            print(url)\n",
    "            print(scrape_horses(url))\n",
    "            \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Saving data to file\n",
    "\n",
    "Most of the time we want to save the data for future use. The most common method is to save the data in a CSV file, a format that is supported by virtually all data analysis software.\n",
    "\n",
    "Package needed:\n",
    "- CSV file reading and writing: https://docs.python.org/3.6/library/csv.html\n",
    "\n",
    "The basic syntax of saving into a CSV file is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"temp.csv\"\n",
    "content = [[1,\"ha\",\"abc\"]]\n",
    "\n",
    "import csv\n",
    "with open(filepath, 'w', newline='') as csvfile:\n",
    "    mywriter = csv.writer(csvfile)\n",
    "    mywriter.writerows(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will incorporate file-saving to our loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170101\n",
      "20170101.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170102\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170103\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170104\n",
      "20170104.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170105\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170106\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170107\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170108\n",
      "20170108.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170109\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170110\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170111\n",
      "20170111.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170112\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170113\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170114\n",
      "20170114.csv saved.\n"
     ]
    }
   ],
   "source": [
    "#The first part of the URL of data source\n",
    "url_front = \"http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/\"\n",
    "\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "#Copy the loop from above and incorporate the csv-saving code\n",
    "for year in range(2017,2018):\n",
    "    for month in range(1,2):\n",
    "        for day in range(1,15):\n",
    "            \n",
    "            #Convert month and day to 2-digit representation\n",
    "            month_2d = '{:02d}'.format(month)\n",
    "            day_2d = '{:02d}'.format(day)\n",
    "            \n",
    "            #Full URL of data source\n",
    "            url = url_front + str(year) + month_2d + day_2d\n",
    "            \n",
    "            #Print the URL so we know the progress so far\n",
    "            print(\"Trying:\",url)\n",
    "            \n",
    "            #Call our function to fetch and process data given the URL\n",
    "            content = scrape_horses(url)\n",
    "            \n",
    "            #Only save if there is something in content\n",
    "            if len(content) > 0:\n",
    "                filepath = str(year)+month_2d+day_2d+\".csv\"\n",
    "                \n",
    "                #This part is just standard CSV-writing code\n",
    "                import csv\n",
    "                with open(filepath, 'w', newline='') as csvfile:\n",
    "                    mywriter = csv.writer(csvfile)\n",
    "                    mywriter.writerows(content)   \n",
    "                    print(filepath,\"saved.\")\n",
    "                    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. Exercise\n",
    "How to get the data for different races? In particular, how should we handle the code for race tracks in the URL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
