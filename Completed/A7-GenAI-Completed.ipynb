{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301b2556-3c62-4c06-9ae6-0ee028c660ea",
   "metadata": {},
   "source": [
    "# Accessing a Generative AI Model through OpenAI API\n",
    "\n",
    "Generative AI models are machine learning models that are capable of generating content.\n",
    "This notebook is going to focus on the most commonly-used type of generative AI models&mdash;the \n",
    "ones that generate text. These models are called *large language models*, or 'LLM' for short.\n",
    "We will not be going into the technical details of how a LLM works at this moment, but rather focus\n",
    "on how to use an LLM as an end user.\n",
    "\n",
    "### Accessing an LLM through Python\n",
    "Although it is very convenient to access an LLM through a browser interface for one-off task, \n",
    "for repetitive task you will generating want to access the model using a program. Model providers \n",
    "will generally provide such access through an *application programming interface*, or 'API' for short.\n",
    "An API defines what sorts of interactions are possible with the model, and how input and output data \n",
    "should look like. \n",
    "\n",
    "The API used by OpenAI, the provider of ChatGPT, is the de facto standard supported by most models.\n",
    "\n",
    "The first step is to set up an OpenAI client. The client requires two piece of information:\n",
    "1. `base_url`: this is the web address of the model provider. If you use OpenAI's model, this can be omited.\n",
    "2. `api_key`: this is a string of text unique to your user account with the model provider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff1848-d882-403f-888d-3799ef0bf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'https://scrp-chat.econ.cuhk.edu.hk/api',\n",
    "    api_key='your_api_key_here',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fd7e0-4945-4c8a-b480-6898c797bd8a",
   "metadata": {},
   "source": [
    "In a production environment, it is best to save this piece of information as an environment variable, so that it will not be saved in your notebook. The easiest way to do so when working in a Jupyter notebook is to put the key in a filed named `.env`, then use the `dotenv` library to set the environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaa489c-056f-4e24-ae3a-32ab7946d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file containing environment variables.\n",
    "# Default is to look for it in the current working directory.\n",
    "home_dir = os.environ[\"HOME\"]\n",
    "load_dotenv(os.path.join(home_dir,\".env\"))\n",
    "\n",
    "# The API key should be saved as an environment variable OPENAI_API_KEY\n",
    "# Optionally set the base_url as OPENAI_BASE_URL in the same file\n",
    "client = OpenAI(\n",
    "    base_url = 'https://scrp-chat.econ.cuhk.edu.hk/api',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec42679-1806-44f2-ad7a-32af3718b4f8",
   "metadata": {},
   "source": [
    "### Model List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd43909-469a-4975-9980-b1a4e1d1660b",
   "metadata": {},
   "source": [
    "To see what models the provider support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d76bd6-d461-41e9-aaa7-d7403713eec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models:\n",
      "Qwen/Qwen2.5-VL-72B-Instruct-AWQ\n",
      "Qwen/Qwen3-32B-FP8\n",
      "abc-test\n",
      "default\n",
      "help\n",
      "image-editor-function\n",
      "openai/gpt-oss-120b\n",
      "openai/gpt-oss-120b\n",
      "reasoning\n",
      "text\n",
      "text-large\n",
      "text-medium\n",
      "text-small\n",
      "vision\n",
      "vision-large\n",
      "vision-medium\n",
      "vision-small\n",
      "zai-org/GLM-4.5-FP8\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "model_ids = sorted([model.id for model in models.data])\n",
    "print(\"Available Models:\")\n",
    "for model_id in model_ids:\n",
    "    print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e206c5-cc8c-46b9-8297-f63097b21ce7",
   "metadata": {},
   "source": [
    "### Calling the Model\n",
    "\n",
    "To call a model, use \n",
    "```python\n",
    "response = client.chat.completions.create(...)\n",
    "```\n",
    "You will need to provide a few pieces of information:\n",
    "- `model`: the name of the model.\n",
    "- `messages`: a list containing the conversation history. Each message should be dictionary with a `role` and a `content`. `role` can be one of:\n",
    "    - `system`: system prompt. Use this to give the model general guidelines that it should follow strictly.\n",
    "    - `user`: prompt entered by the user. \n",
    "    - `assistant`: response from the model. \n",
    "    - `tool`: response from tools the model can use.\n",
    "- Additional settings such as temperature and number of samples:\n",
    "    - `temperature`:\n",
    "    - `n`:\n",
    "\n",
    "The response will be recorded in\n",
    "```python\n",
    "response.choices[0].message.content\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63e23de-39e8-43a4-8171-29c645e69996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong is a Special Administrative Region (SAR) of the People’s Republic of China. Geographically, it is located on the southeastern coast of China, at the mouth of the Pearl River Delta. \n",
      "\n",
      "- **Coordinates:** approximately 22.3° N latitude, 114.2° E longitude.  \n",
      "- **Borders:**  \n",
      "  - **South:** South China Sea (including Victoria Harbour).  \n",
      "  - **North:** The mainland Chinese city of Shenzhen in Guangdong Province.  \n",
      "- **Proximity to major cities:**  \n",
      "  - About 30 km (≈ 19 mi) north of Macau.  \n",
      "  - Roughly 120 km (≈ 75 mi) west of Guangzhou, the capital of Guangdong Province.  \n",
      "\n",
      "On a world map, you’ll find Hong Kong on the eastern side of the Asian continent, just east of mainland China’s southern coast and opposite the island of Taiwan across the South China Sea.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where is Hong Kong?\"},\n",
    "  ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c5b33-7762-4625-aecb-e5d5d140566f",
   "metadata": {},
   "source": [
    "### Example: Scrapping Webpage and Extract Information with LLM\n",
    "\n",
    "We first scrape the webpage with Selenium + Beautiful Soup,\n",
    "but unlike before, we do not manually find the elements we need.\n",
    "Instead, we export a stripped version of the webpage's source code,\n",
    "then uses an LLM to extract the information we need. \n",
    "We use stripped version of the source code to reduce the number of \n",
    "tokens fed to the LLM, so as not to exceed the LLM's context length,\n",
    "and it also improves accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1818990-b694-40a9-a4f9-af3d094644f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "\n",
    "def get_stripped_page_source(url):\n",
    "    # Function to access a page and save all horses into a list\n",
    "\n",
    "    # Fetch the page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Is there anything?\n",
    "    if driver.page_source.find(\"No information.\") != -1:\n",
    "        return \"\"\n",
    "    \n",
    "    # Wait 30 secs so that the dynamic content has time to load.\n",
    "    # Proceed to next date if page doesn't load.\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"f_fs13\")))\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    # Load the page into BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    return soup.get_text(strip=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343caa8a-c0e7-4b8c-be39-a4ce2162bc34",
   "metadata": {},
   "source": [
    "Scrape the webpage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928e63bb-2a1a-4f3f-9b21-9daf09dc2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up selenium to use Firefox\n",
    "options = Options()\n",
    "options.add_argument('-headless') #No need to open a browser window\n",
    "\n",
    "driver = webdriver.Firefox(options=options)\n",
    "page_source = get_stripped_page_source('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST')\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d12c9-8a13-4413-ae97-f1b67e720b73",
   "metadata": {},
   "source": [
    "Let us take a look at the stripped source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84dc2a-b47e-4648-b9bf-94a7b65e39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffea03-c586-4daa-92bb-451fbcb5d6c1",
   "metadata": {},
   "source": [
    "Now we feed the source code to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c243c3-ed62-4837-a169-b2ac2e6cd931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place,Horse No,Horse,Jockey,Trainer,Details,Finish Time,Win Odds\n",
      "1,110,\"JOLLY JOLLY (T087)\",\"K Teetan\",\"P O'Sullivan\",\"114121413-11111\",\"1:22.05\",\"2.628\"\n",
      "2,105,\"PEOPLE'S KNIGHT (T305)\",\"T Berry\",\"J Moore\",\"1191163822422\",\"1:22.39\",\"5.7312\"\n",
      "3,176,\"RUN FORREST (T176)\",\"J Moreira\",\"C S Shum\",\"11511351031410103\",\"1:22.54\",\"3.944\"\n",
      "4,167,\"MODERN TSAR (S167)\",\"B Prebble\",\"W Y So\",\"1231101114-3/4913134\",\"1:22.80\",\"1.353\"\n",
      "5,114,\"MAGNETISM (V114)\",\"G Lerena\",\"D E Ferraris\",\"125113034-3/47665\",\"1:22.81\",\"5.261\"\n",
      "6,236,\"ENORMOUS HONOUR (T236)\",\"N Rawiller\",\"Y S Tsui\",\"131112795-1/4111212\",\"1:22.87\",\"10.79\"\n",
      "7,299,\"HAPPY JOURNEY (S299)\",\"H W Lai\",\"S Woods\",\"114104056-1/25777\",\"1:23.08\",\"12.1814\"\n",
      "8,202,\"WINGOLD (T202)\",\"M L Yeung\",\"A Lee\",\"1111154126-1/2131414\",\"1:23.11\",\"33.1911\"\n",
      "9,351,\"OVETT (P351)\",\"H N Wong\",\"A T Millard\",\"105115347-1/43239\",\"1:23.20\",\"4.1105\"\n",
      "10,442,\"PAKISTAN BABY (S442)\",\"D Whyte\",\"A S Cruz\",\"121102377-1/46111110\",\"1:23.22\",\"12.116\"\n",
      "11,382,\"SUPER FLUKE (T382)\",\"M Demuro\",\"D Cruz\",\"1201109147-3/443411\",\"1:23.27\",\"65.127\"\n",
      "12,325,\"JUN GONG (N325)\",\"C Y Ho\",\"C H Yip\",\"1151147610-1/410981\",\"1:23.68\",\"31.32\"\n",
      "13,297,\"LAUGH OUT LOUD (P297)\",\"G Mosse\",\"K L Man\",\"1261127110-1/285513\",\"1:23.73\",\"151.413\"\n",
      "14,239,\"TEN SPEED (T239)\",\"Y T Cheng\",\"C W Chang\",\"1161033212-3/4128914\",\"1:24.08\",\"2.02\"\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"The following webpage contains horse racing results. \n",
    "                                Please extract the result table and return it in comma-delimited\n",
    "                                CSV format. No explanation is needed.\n",
    "                                {page_source}\n",
    "                                \"\"\"},\n",
    "  ],\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7a6b6-dba0-4d34-b9cc-51c0e5dd6cc8",
   "metadata": {},
   "source": [
    "If the output is unreliable, you can use Beauitful Soup to locate the table, and provide only the source code of the table to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b588f2-c73b-43e9-acac-658932313d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stripped_page_source(url):\n",
    "    # Fetch the page\n",
    "    driver.get(url)\n",
    "    # Load the page into Beautiful Soup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # Get the result table\n",
    "    result_table = soup.find(\"table\", class_=\"f_tac\")\n",
    "    if result_table:\n",
    "        return result_table.prettify()\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59b949-127e-4574-a756-e39265dce921",
   "metadata": {},
   "source": [
    "Let us try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97139608-77d4-4bf3-a861-d090d5ccf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get source code of the table\n",
    "driver = webdriver.Firefox(options=options)\n",
    "page_source = get_stripped_page_source('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST')\n",
    "driver.quit()\n",
    "\n",
    "# Feed LLM the table\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"The following webpage contains horse racing results. \n",
    "                                Please extract the result table and return it in comma-delimited\n",
    "                                CSV format. No explanation is needed.\n",
    "                                {page_source}\n",
    "                                \"\"\"},\n",
    "  ],\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa751c-3734-489f-95ee-15f77c988107",
   "metadata": {},
   "source": [
    "Finally, we write the output to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ae1ba1-2ad7-4150-9b2b-3c1651b26031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result.csv\", \"a\") as f:\n",
    "  f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3f309-01ff-4d4d-8ba6-74c47208ac51",
   "metadata": {},
   "source": [
    "We can put everything together in one function\n",
    "and use it in a loop to save the information we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ad9173-f885-4a57-b560-3bcf152c22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape results\n",
    "\n",
    "def scrape_webpage(url, prompt):\n",
    "    page_source = get_stripped_page_source(url)\n",
    "    if page_source != \"\":\n",
    "        response = client.chat.completions.create(\n",
    "          model=\"default\",\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt + page_source},\n",
    "          ],\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf2993-9d6b-4521-bd90-a68834c67db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170101\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170102\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170103\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170104\n"
     ]
    }
   ],
   "source": [
    "# The first part of the URL of data source\n",
    "url_front = \"http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/\"\n",
    "prompt = \"\"\"The following webpage contains horse racing results. \n",
    "            Please extract the result table and return it in comma-delimited\n",
    "            CSV format. No explanation is needed.\n",
    "            \"\"\"\n",
    "\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "try:\n",
    "    # Copy the loop from above and incorporate the csv-saving code\n",
    "    for year in range(2017,2018):\n",
    "        for month in range(1,2):\n",
    "            for day in range(1,32):\n",
    "                \n",
    "                # Convert month and day to 2-digit representation\n",
    "                month_2d = '{:02d}'.format(month)\n",
    "                day_2d = '{:02d}'.format(day)\n",
    "                \n",
    "                # Full URL of data source\n",
    "                url = url_front + str(year) + month_2d + day_2d\n",
    "                \n",
    "                # Print the URL so we know the progress so far\n",
    "                print(\"Trying:\",url)\n",
    "                \n",
    "                # Call our function to fetch and process data given the URL\n",
    "                content = scrape_webpage(url, prompt)\n",
    "                \n",
    "                # Only save if there is something in content\n",
    "                if content is not None:\n",
    "                    filepath = str(year)+month_2d+day_2d+\".csv\"\n",
    "                    \n",
    "                    # Save to file\n",
    "                    with open(filepath, \"a\") as f:\n",
    "                        f.write(output)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)    \n",
    "                    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e0433-1c61-4ae3-abf3-63232fe2c7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
