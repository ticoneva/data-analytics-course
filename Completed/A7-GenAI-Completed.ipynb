{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301b2556-3c62-4c06-9ae6-0ee028c660ea",
   "metadata": {},
   "source": [
    "# Accessing a Generative AI Model through OpenAI API\n",
    "\n",
    "Version: 2025-10-5\n",
    "\n",
    "Generative AI models are machine learning models that are capable of generating content.\n",
    "This notebook is going to focus on the most commonly-used type of generative AI models&mdash;the \n",
    "ones that generate text. These models are called *large language models*, or 'LLM' for short.\n",
    "We will not be going into the technical details of how a LLM works at this moment, but rather focus\n",
    "on how to use an LLM as an end user.\n",
    "\n",
    "### A. Accessing an LLM through Python\n",
    "Although it is very convenient to access an LLM through a browser interface for one-off task, \n",
    "for repetitive task you will generating want to access the model using a program. Model providers \n",
    "will generally provide such access through an *application programming interface*, or 'API' for short.\n",
    "An API defines what sorts of interactions are possible with the model, and how input and output data \n",
    "should look like. \n",
    "\n",
    "The API used by OpenAI, the provider of ChatGPT, is the de facto standard supported by most models.\n",
    "\n",
    "The first step is to set up an OpenAI client. The client requires two piece of information:\n",
    "1. `base_url`: this is the web address of the model provider. If you use OpenAI's model, this can be omited.\n",
    "2. `api_key`: this is a string of text unique to your user account with the model provider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff1848-d882-403f-888d-3799ef0bf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'https://scrp-chat.econ.cuhk.edu.hk/api',\n",
    "    api_key='your_api_key_here',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fd7e0-4945-4c8a-b480-6898c797bd8a",
   "metadata": {},
   "source": [
    "In a production environment, it is best to save this piece of information as an environment variable, so that it will not be saved in your notebook. The easiest way to do so when working in a Jupyter notebook is to put the key in a filed named `.env`, then use the `dotenv` library to set the environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaa489c-056f-4e24-ae3a-32ab7946d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file containing environment variables.\n",
    "# Default is to look for it in the current working directory.\n",
    "home_dir = os.environ[\"HOME\"]\n",
    "load_dotenv(os.path.join(home_dir,\".env\"))\n",
    "\n",
    "# The API key should be saved as an environment variable OPENAI_API_KEY\n",
    "# Optionally set the base_url as OPENAI_BASE_URL in the same file\n",
    "client = OpenAI(\n",
    "    base_url = 'https://scrp-chat.econ.cuhk.edu.hk/api',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd43909-469a-4975-9980-b1a4e1d1660b",
   "metadata": {},
   "source": [
    "### B. Model List\n",
    "\n",
    "To see what models the provider support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d76bd6-d461-41e9-aaa7-d7403713eec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models:\n",
      "Qwen/Qwen2.5-VL-72B-Instruct-AWQ\n",
      "Qwen/Qwen3-32B-FP8\n",
      "abc-test\n",
      "default\n",
      "help\n",
      "image-editor-function\n",
      "openai/gpt-oss-120b\n",
      "openai/gpt-oss-120b\n",
      "reasoning\n",
      "text\n",
      "text-large\n",
      "text-medium\n",
      "text-small\n",
      "vision\n",
      "vision-large\n",
      "vision-medium\n",
      "vision-small\n",
      "zai-org/GLM-4.5-FP8\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "model_ids = sorted([model.id for model in models.data])\n",
    "print(\"Available Models:\")\n",
    "for model_id in model_ids:\n",
    "    print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e206c5-cc8c-46b9-8297-f63097b21ce7",
   "metadata": {},
   "source": [
    "### C. Calling the Model\n",
    "\n",
    "To call a model, use \n",
    "```python\n",
    "response = client.chat.completions.create(...)\n",
    "```\n",
    "You will need to provide a few pieces of information:\n",
    "- `model`: the name of the model.\n",
    "- `messages`: a list containing the conversation history. Each message should be dictionary with a `role` and a `content`. `role` can be one of:\n",
    "    - `system`: system prompt. Use this to give the model general guidelines that it should follow strictly.\n",
    "    - `user`: prompt entered by the user. \n",
    "    - `assistant`: response from the model. \n",
    "    - `tool`: response from tools the model can use.\n",
    "- Additional settings such as temperature and number of samples:\n",
    "    - `temperature`: Adjust the randomness of the response. 0 is the lowest setting.\n",
    "      Default is model specfic, around 0.6-0.8.\n",
    "    - `n`: number of responses you want the model to generate. Default is 1.\n",
    "\n",
    "The response will be recorded in\n",
    "```python\n",
    "response.choices[0].message.content\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63e23de-39e8-43a4-8171-29c645e69996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong is a Special Administrative Region (SAR) on the southeastern coast of **the People’s Republic of China**.  \n",
      "\n",
      "- **Geographic setting**: It sits on the eastern side of the Pearl River Delta, facing the **South China Sea**. The region consists of Hong Kong Island, the Kowloon Peninsula, the New Territories (a large area north of Kowloon that borders the mainland province of **Guangdong**), and more than 200 outlying islands.  \n",
      "- **Coordinates**: Approximately **22°17′ N latitude, 114°10′ E longitude**.  \n",
      "- **Borders**: To the north and west it is contiguous with Guangdong province (the city of Shenzhen lies just across the border), while the southern and eastern sides are coastline along the sea.  \n",
      "\n",
      "In summary, Hong Kong is located on the southern edge of mainland China, just opposite the bustling metropolis of Shenzhen, and serves as a major port and international financial hub.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where is Hong Kong?\"},\n",
    "  ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c5b33-7762-4625-aecb-e5d5d140566f",
   "metadata": {},
   "source": [
    "### D. Example: Scrapping Webpage and Extract Information with LLM\n",
    "\n",
    "We first scrape the webpage with Selenium + Beautiful Soup,\n",
    "but unlike before, we do not manually find the elements we need.\n",
    "Instead, we export a stripped version of the webpage's source code,\n",
    "then uses an LLM to extract the information we need. \n",
    "\n",
    "Because LLMs can only process a limited amount of text input, called \n",
    "*context length*, and slows down as the context length goes up, \n",
    "it is usually wise to use Beautiful Soup to locate\n",
    "as precious as possible what you need, before passing the source code\n",
    "to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343caa8a-c0e7-4b8c-be39-a4ce2162bc34",
   "metadata": {},
   "source": [
    "Scrape the webpage in full:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e046463a-426c-4739-a61f-fa89a73197ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works with static content.\n",
    "# See A6-Data-Scrping-Completed for a version that works with dynamic content.\n",
    "import requests\n",
    "def get_page_source(url, strip=False):\n",
    "    # Function to access a page and save all horses into a list\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    return soup.get_text(strip=strip)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffea03-c586-4daa-92bb-451fbcb5d6c1",
   "metadata": {},
   "source": [
    "Now we feed the source code to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02c243c3-ed62-4837-a169-b2ac2e6cd931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing took: 19.73\n",
      "Pla.,Horse No.,Horse,Jockey,Trainer,Act. Wt.,Declar. Horse Wt.,Dr.,LBW,RunningPosition,Finish Time,Win Odds\n",
      "1,10,JOLLY JOLLY (T087),P O'Sullivan,K Teetan,114,1214,13,-,1,1:22.05,2.6\n",
      "2,8,PEOPLE'S KNIGHT (T305),T Berry,J Moore,119,1163,8,2,2,1:22.39,5.7\n",
      "3,12,RUN FORREST (T176),J Moreira,C S Shum,115,1135,10,3,3,1:22.54,3.9\n",
      "4,4,MODERN TSAR (S167),B Prebble,W Y So,123,1101,11,4-3/4,4,1:22.80,13\n",
      "5,3,MAGNETISM (V114),G Lerena,D E Ferraris,125,1130,3,4-3/4,5,1:22.81,52\n",
      "6,1,ENORMOUS HONOUR (T236),N Rawiller,Y S Tsui,131,1127,9,5-1/4,6,1:22.87,10\n",
      "7,9,HAPPY JOURNEY (S299),H W Lai,S Woods,114,1040,5,6-1/2,7,1:23.08,121\n",
      "8,14,WINGOLD (T202),M L Yeung,A Lee,111,1154,12,6-1/2,8,1:23.11,331\n",
      "9,11,OVETT (P351),H N Wong,A T Millard,105,1153,4,7-1/4,9,1:23.20,41\n",
      "10,5,PAKISTAN BABY (S442),D Whyte,A S Cruz,121,1023,7,7-1/4,10,1:23.22,12\n",
      "11,6,SUPER FLUKE (T382),M Demuro,D Cruz,120,1109,14,7-3/4,11,1:23.27,65\n",
      "12,7,JUN GONG (N325),C Y Ho,C H Yip,115,1147,6,10-1/4,12,1:23.68,83\n",
      "13,2,LAUGH OUT LOUD (P297),G Mosse,K L Man,126,1127,1,10-1/2,13,1:23.73,15\n",
      "14,13,TEN SPEED (T239),Y T Cheng,C W Chang,116,1033,2,12-3/4,14,1:24.08,202\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "page_source = get_page_source('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST')\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "start = time.time()\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"The following webpage contains horse racing results. \n",
    "                                Please extract the result table and return it in comma-delimited\n",
    "                                CSV format. No explanation is needed.\n",
    "                                {page_source}\n",
    "                                \"\"\"},\n",
    "  ],\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "print(\"Processing took: {:.2f}\".format(time.time() - start))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74528447-3ab0-44ff-9495-0d21ef499975",
   "metadata": {},
   "source": [
    "You can strip white space by setting `strip = True` in `get_page_source()`, \n",
    "but it appears to drastically lower the quality of the LLM's output.\n",
    "The likely reason for this is that during training, the LLM has learnt to \n",
    "use the leading and trailing white space in understanding the content. \n",
    "Removing the whitespace therefore make the content harder to understand,\n",
    "just like it would be for an actual human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d3d0403-cfbe-49b7-a1a1-3c0250eeb63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing took: 20.78\n",
      "Horse No.,Horse,Jockey,Trainer,Act.Wt,Decl.Wt,Draw,LBW,Running Pos,Finish Time,Win Odds\n",
      "1,JOLLY JOLLY,K Teetan,P O'Sullivan,114,121,13,-11,1,1:22.05,2.62\n",
      "2,PEOPLE'S KNIGHT,T Berry,J Moore,119,116,3,8,2,1:22.39,5.73\n",
      "3,RUN FORREST,J Moreira,C S Shum,115,113,5,10,3,1:22.54,3.94\n",
      "4,MODERN TSAR,B Prebble,W Y So,123,110,11,4,-3/49,1:22.80,13.53\n",
      "5,MAGNETISM,G Lerena,D E Ferraris,125,113,0,34,-3/47,1:22.81,53.65\n",
      "6,ENORMOUS HONOUR,N Rawiller,Y S Tsui,131,112,79,5,-1/41,1:22.87,107.9\n",
      "7,HAPPY JOURNEY,H W Lai,S Woods,114,104,0,56,-1/25,1:23.08,121.8\n",
      "8,WINGOLD,M L Yeung,A Lee,111,115,4,126,-1/21,1:23.11,131.9\n",
      "9,OVETT,H N Wong,A T Millard,105,115,3,47,-1/43,1:23.20,41.1\n",
      "10,PAKISTAN BABY,D Whyte,A S Cruz,121,102,3,77,-1/46,1:23.22,111.1\n",
      "11,SUPER FLUKE,M Demuro,D Cruz,120,110,9,14,7,-3/44,1:23.27,65.12\n",
      "12,JUN GONG,C Y Ho,C H Yip,115,114,7,61,0,-1/41,1:23.68,98.1\n",
      "13,LAUGH OUT LOUD,G Mosse,K L Man,126,112,7,11,0,-1/28,1:23.73,151.4\n",
      "14,TEN SPEED,Y T Cheng,C W Chang,116,103,3,2,12,-3/41,1:24.08,202\n",
      "15,Note:Special Incidents IndexDividendPool,,,,\n",
      "16,Winning Combination,,,,\n",
      "17,WIN,102,6.50,,,,\n",
      "18,PLACE,1013.00,820.00,1218.00,,,,\n",
      "19,QUINELLA,8,1010.9,,,\n",
      "20,QUINELLA PLACE,8,1040.5,10,1229.00,8,1249.50,\n",
      "21,PICK 1(COMPOSITE WIN),A1,NOT WIN,A2,18.5,\n",
      "22,Detail TIERCE,10,8,126,58.00,\n",
      "23,TRIO,8,10,121,12.00,\n",
      "24,FIRST,44,8,10,123,04.00,\n",
      "25,QUARTET,10,8,12,46,753.00,\n",
      "26,Dividend Note: For Winning Combination, \"F\" denotes \"Any Combination\" while \"M\" denotes \"Any Order\".,,,,\n",
      "27,Racing Running Position Photos,,,,\n",
      "28,Comments on Running,,,,\n",
      "29,Racing Incident Report,,,,\n",
      "30,RUN FORREST began awkwardly and lost ground.,,,,\n",
      "31,WINGOLD was crowded for room on jumping between JOLLY JOLLY and MODERN TSAR which got its head on the side and shifted out.,,,,\n",
      "32,LAUGH OUT LOUD and TEN SPEED bumped on jumping.,,,,\n",
      "33,MAGNETISM began only fairly and then shortly after the start was steadied away from the heels of OVETT which shifted in.,,,,\n",
      "34,Approaching and passing the 1100 Metres, MAGNETISM got its head up when travelling keenly and awkwardly placed close to the heels of PEOPLE'S KNIGHT which was being steadied to allow JOLLY JOLLY to cross.,,,,\n",
      "35,Passing the 900 Metres, LAUGH OUT LOUD became unbalanced when racing tight inside PEOPLE'S KNIGHT which got its head on the side and shifted in away from SUPER FLUKE (M Demuro).,,\n",
      "36,Near the 650 Metres, SUPER FLUKE and PEOPLE'S KNIGHT raced tight and then approaching the 600 Metres those horses bumped and as a result became unbalanced.,,\n",
      "37,At the 500 Metres, MODERN TSAR was awkwardly placed close to the heels of PAKISTAN BABY.,,\n",
      "38,Passing the 500 Metres, WINGOLD got its head up when awkwardly placed close to the heels of ENORMOUS HONOUR.,,\n",
      "39,Near the 450 Metres, ENORMOUS HONOUR shifted out and bumped the hindquarters of PAKISTAN BABY which became unbalanced.,,\n",
      "40,Near the 350 Metres, WINGOLD was shifted out away from the heels of ENORMOUS HONOUR which was disappointed for running between PAKISTAN BABY and HAPPY JOURNEY.,,\n",
      "41,In the Straight, JUN GONG raced with its head on the side and lay in under pressure.,,\n",
      "42,For the majority of the race, SUPER FLUKE travelled wide and without cover.,,\n",
      "43,A veterinary inspection of LAUGH OUT LOUD and PAKISTAN BABY immediately following the race did not show any significant findings.,,\n",
      "44,JOLLY JOLLY and PEOPLE'S KNIGHT were sent for sampling.,,\n",
      "45,Breed of the Winning Horse-Online,JOLLY JOLLY,Sire: Stratum,Dam: Paolino,Remark: Aerial Virtual Replay is provided by 3rd parties, for personal infotainment only.,,\n",
      "46,The Hong Kong Jockey Club © 2000-2017 All rights reserved.,,,,\n",
      "47,,,,,,,,,,\n",
      "\n",
      "*Note: The table above captures the race result entries and the subsequent narrative sections as provided in the source.*\n"
     ]
    }
   ],
   "source": [
    "page_source = get_page_source('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST',\n",
    "                              strip=True)\n",
    "start = time.time()\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"The following webpage contains horse racing results. \n",
    "                                Please extract the result table and return it in comma-delimited\n",
    "                                CSV format. No explanation is needed.\n",
    "                                {page_source}\n",
    "                                \"\"\"},\n",
    "  ],\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "print(\"Processing took: {:.2f}\".format(time.time() - start))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7a6b6-dba0-4d34-b9cc-51c0e5dd6cc8",
   "metadata": {},
   "source": [
    "To speed up the processing and make the model's output more accurate, you can use Beauitful Soup to locate the table, and provide only the source code of the table to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23220cb0-9891-416a-9a9e-e71fed0a2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_page_source(url, strip=False):\n",
    "    # Function to access a page and save all horses into a list\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    # Get the result table\n",
    "    result_table = soup.find(\"table\", class_=\"f_tac\")\n",
    "    if result_table:\n",
    "        return result_table.prettify()\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59b949-127e-4574-a756-e39265dce921",
   "metadata": {},
   "source": [
    "Let us try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97139608-77d4-4bf3-a861-d090d5ccf3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing took: 12.99\n",
      "Pla.,Horse No.,Horse,Jockey,Trainer,Act. Wt.,Declar. Horse Wt.,Dr.,LBW,Running Position,Finish Time,Win Odds\n",
      "1,10,JOLLY JOLLY,K Teetan,P O'Sullivan,114,1214,13,-,\"1 1 1 1\",1:22.05,2.6\n",
      "2,8,PEOPLE'S KNIGHT,T Berry,J Moore,119,1163,8,2,\"2 4 2 2\",1:22.39,5.7\n",
      "3,12,RUN FORREST,J Moreira,C S Shum,115,1135,10,3,\"14 10 10 3\",1:22.54,3.9\n",
      "4,4,MODERN TSAR,B Prebble,W Y So,123,1101,11,4-3/4,\"9 13 13 4\",1:22.80,13\n",
      "5,3,MAGNETISM,G Lerena,D E Ferraris,125,1130,3,4-3/4,\"7 6 6 5\",1:22.81,52\n",
      "6,1,ENORMOUS HONOUR,N Rawiller,Y S Tsui,131,1127,9,5-1/4,\"11 12 12 6\",1:22.87,10\n",
      "7,9,HAPPY JOURNEY,H W Lai,S Woods,114,1040,5,6-1/2,\"5 7 7 7\",1:23.08,121\n",
      "8,14,WINGOLD,M L Yeung,A Lee,111,1154,12,6-1/2,\"13 14 14 8\",1:23.11,331\n",
      "9,11,OVETT,H N Wong,A T Millard,105,1153,4,7-1/4,\"3 2 3 9\",1:23.20,41\n",
      "10,5,PAKISTAN BABY,D Whyte,A S Cruz,121,1023,7,7-1/4,\"6 11 11 10\",1:23.22,12\n",
      "11,6,SUPER FLUKE,M Demuro,D Cruz,120,1109,14,7-3/4,\"4 3 4 11\",1:23.27,65\n",
      "12,7,JUN GONG,C Y Ho,C H Yip,115,1147,6,10-1/4,\"10 9 8 12\",1:23.68,83\n",
      "13,2,LAUGH OUT LOUD,G Mosse,K L Man,126,1127,1,10-1/2,\"8 5 5 13\",1:23.73,15\n",
      "14,13,TEN SPEED,Y T Cheng,C W Chang,116,1033,2,12-3/4,\"12 8 9 14\",1:24.08,202\n"
     ]
    }
   ],
   "source": [
    "page_source = get_page_source('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20151213/ST',\n",
    "                              strip=True)\n",
    "start = time.time()\n",
    "response = client.chat.completions.create(\n",
    "  model=\"default\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"The following webpage contains horse racing results. \n",
    "                                Please extract the result table and return it in comma-delimited\n",
    "                                CSV format. No explanation is needed.\n",
    "                                {page_source}\n",
    "                                \"\"\"},\n",
    "  ],\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "print(\"Processing took: {:.2f}\".format(time.time() - start))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e7e0f-cb94-41d3-814a-277b8f280d0d",
   "metadata": {},
   "source": [
    "### E. Outputing to File\n",
    "\n",
    "Because the LLM has done the formatting, we directly write\n",
    "the output to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ae1ba1-2ad7-4150-9b2b-3c1651b26031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result.csv\", \"w\") as f:\n",
    "  f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3f309-01ff-4d4d-8ba6-74c47208ac51",
   "metadata": {},
   "source": [
    "### F. Scrape Multiple Pages\n",
    "\n",
    "We can put everything together in one function\n",
    "and use it in a loop to save the information we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ad9173-f885-4a57-b560-3bcf152c22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape results\n",
    "\n",
    "def scrape_webpage(url, prompt):\n",
    "    page_source = get_page_source(url)\n",
    "    if page_source != \"\":\n",
    "        response = client.chat.completions.create(\n",
    "          model=\"default\",\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt + page_source},\n",
    "          ],\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1cf2993-9d6b-4521-bd90-a68834c67db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170101\n",
      "20170101.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170102\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170103\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170104\n",
      "20170104.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170105\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170106\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170107\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170108\n",
      "20170108.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170109\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170110\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170111\n",
      "20170111.csv saved.\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170112\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170113\n",
      "Trying: http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20170114\n",
      "20170114.csv saved.\n"
     ]
    }
   ],
   "source": [
    "# The first part of the URL of data source\n",
    "url_front = \"http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/\"\n",
    "prompt = \"\"\"The following webpage may contain horse racing results in a table. \n",
    "            If it does, please extract the result table and return it in \n",
    "            comma-delimited CSV format. If not, just return an empty string.\n",
    "            No explanation is needed.\n",
    "            \"\"\"\n",
    "\n",
    "# Copy the loop from above and incorporate the csv-saving code\n",
    "for year in range(2017,2018):\n",
    "    for month in range(1,2):\n",
    "        for day in range(1,15):\n",
    "            \n",
    "            # Convert month and day to 2-digit representation\n",
    "            month_2d = '{:02d}'.format(month)\n",
    "            day_2d = '{:02d}'.format(day)\n",
    "            \n",
    "            # Full URL of data source\n",
    "            url = url_front + str(year) + month_2d + day_2d\n",
    "            \n",
    "            # Print the URL so we know the progress so far\n",
    "            print(\"Trying:\",url)\n",
    "            \n",
    "            # Call our function to fetch and process data given the URL\n",
    "            output = scrape_webpage(url, prompt)\n",
    "            \n",
    "            # Only save if there is something in content\n",
    "            if output is not None:\n",
    "                filepath = str(year)+month_2d+day_2d+\".csv\"\n",
    "                \n",
    "                # Save to file\n",
    "                with open(filepath, \"w\") as f:\n",
    "                    f.write(output)\n",
    "                    print(f\"{filepath} saved.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
