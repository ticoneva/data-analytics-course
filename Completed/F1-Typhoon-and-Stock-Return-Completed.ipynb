{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typhoon and Stock Return\n",
    "\n",
    "In this tutorial, we will investigate whether the stock market performs abnormally after a strong typhoon. We will make extensive use of the data-handling package ```pandas```, the statistical functions of ```scipy``` and the statistics package ```statsmodel```.\n",
    "\n",
    "## A. Data Cleaning\n",
    "\n",
    "### A1. Typhoon data\n",
    "\n",
    "The typhoon data is obtained from the Hong Kong Observatory. \n",
    "Each row contains data for a particular signal. Since typhoons often go through\n",
    "several signals, there are multiple rows for each typhoon.\n",
    "\n",
    "We will first do some preprocessing:\n",
    "- Since we are only interested in the effect of strong typhoons, we will only keep typhoons that have a maximum signal at or above No. 8. \n",
    "- We will also keep record of the date each typhoon went below Signal No. 8.\n",
    "\n",
    "A few notable pandas techniques that we will be using:\n",
    "- To **select rows** out of a DataFrame whenever a certain column satisfying an inequality, use\n",
    "```python\n",
    "DataFrame[DataFrame['column_name'] >= value]\n",
    "```\n",
    "More generally, you can select rows by supplying a list of True/False values.\n",
    "\n",
    "\n",
    "- To convert a column to pandas **datatime** format, use ```pd.to_datetime()```.\n",
    "  You can then extract individual date components by ```.dt.year```, ```.dt.month``` etc.\n",
    "  For example, to extract year out of a column called *date*, you can write:\n",
    "  ```python\n",
    "  DataFrame('date') = pd.to_datetime(DataFrame('date'))\n",
    "  DataFrame('year') = DataFrame('date').dt.year \n",
    "  ```\n",
    "\n",
    "\n",
    "- There are two ways to calculate the summary statistic of column B **grouped by** values of column A:\n",
    "    - To collapse to one row per group, use:\n",
    "        ```python\n",
    "        DataFrame.groupby('column_A')['column_B'].ops()\n",
    "        ```\n",
    "        where `opts()` can be operations such as `mean()`, `max()`, etc. \n",
    "        Note that this method returns a pandas Series instead of a DataFrame. \n",
    "        To get a DataFrame, append `.to_frame()` at the end.\n",
    "    - If you want to maintain the original number of rows, use:\n",
    "        ```python\n",
    "        DataFrame.groupby('column_A')['column_B'].transform('ops')\n",
    "        ```\n",
    "\n",
    "- To **drop duplicates**, use\n",
    "```python\n",
    "DataFrame.drop_duplicates(subset,keep)\n",
    "```\n",
    "    - `subset`: by default pandas consider two rows to be duplicates only \n",
    "    if they are identical for all columns. You can specify a narrower set of columns here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Signal_max</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEO</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MAGGIE</td>\n",
       "      <td>9</td>\n",
       "      <td>1999-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>YORK</td>\n",
       "      <td>10</td>\n",
       "      <td>1999-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>YUTU</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>HAGUPIT</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>IMBUDO</td>\n",
       "      <td>8</td>\n",
       "      <td>2003-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>DUJUAN</td>\n",
       "      <td>9</td>\n",
       "      <td>2003-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>KOMPASU</td>\n",
       "      <td>8</td>\n",
       "      <td>2004-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>PABUK</td>\n",
       "      <td>8</td>\n",
       "      <td>2007-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>FENGSHEN</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>KAMMURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NURI</td>\n",
       "      <td>9</td>\n",
       "      <td>2008-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>HAGUPIT</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>MOLAVE</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>GONI</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>KOPPU</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NESAT</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>DOKSURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>VICENTE</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>KAI-TAK</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>USAGI</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>KALMAEGI</td>\n",
       "      <td>8</td>\n",
       "      <td>2014-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>LINFA</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>NIDA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>HAIMA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>MERBOK</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ROKE</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>HATO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>PAKHAR</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>KHANUN</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>MANGKHUT</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-09-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  Signal_max   end_date\n",
       "2         LEO           8 1999-05-02\n",
       "8      MAGGIE           9 1999-06-07\n",
       "17        SAM           8 1999-08-23\n",
       "25       YORK          10 1999-09-16\n",
       "30        CAM           8 1999-09-26\n",
       "52       UTOR           8 2001-07-06\n",
       "57       YUTU           8 2001-07-25\n",
       "66    HAGUPIT           8 2002-09-12\n",
       "72     IMBUDO           8 2003-07-24\n",
       "80     DUJUAN           9 2003-09-03\n",
       "87    KOMPASU           8 2004-07-16\n",
       "111     PABUK           8 2007-08-10\n",
       "121  FENGSHEN           8 2008-06-25\n",
       "126   KAMMURI           8 2008-08-06\n",
       "133      NURI           9 2008-08-23\n",
       "139   HAGUPIT           8 2008-09-24\n",
       "152    MOLAVE           9 2009-07-19\n",
       "157      GONI           8 2009-08-05\n",
       "166     KOPPU           8 2009-09-15\n",
       "190     NESAT           8 2011-09-29\n",
       "201   DOKSURI           8 2012-06-30\n",
       "209   VICENTE          10 2012-07-24\n",
       "214   KAI-TAK           8 2012-08-17\n",
       "229      UTOR           8 2013-08-14\n",
       "235     USAGI           8 2013-09-23\n",
       "245  KALMAEGI           8 2014-09-16\n",
       "251     LINFA           8 2015-07-09\n",
       "263      NIDA           8 2016-08-02\n",
       "276     HAIMA           8 2016-10-21\n",
       "282    MERBOK           8 2017-06-13\n",
       "286      ROKE           8 2017-07-23\n",
       "294      HATO          10 2017-08-23\n",
       "299    PAKHAR           8 2017-08-27\n",
       "308    KHANUN           8 2017-10-15\n",
       "328  MANGKHUT          10 2018-09-17"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import data and keep only signal 8 or above\n",
    "typhoon_data = pd.read_excel(\"../Data/typhoon_hk.xlsx\")\n",
    "typhoon_data = typhoon_data[typhoon_data[\"Signal\"]>=8]\n",
    "\n",
    "# Convert date to pandas datatime format and extract year\n",
    "typhoon_data[\"end_date\"] = pd.to_datetime(typhoon_data[\"end_date\"])\n",
    "typhoon_data['year'] = typhoon_data['end_date'].dt.year\n",
    "\n",
    "# Find the highest signal for each typhoon and store it in 'Signal_max'\n",
    "typhoon_data['Signal_max'] = typhoon_data.groupby(['Name','year'])['Signal'].transform('max')\n",
    "\n",
    "# Keep only the last date for each typhoon\n",
    "typhoon_data = typhoon_data.drop_duplicates(subset=['Name','year'],keep=\"last\")\n",
    "\n",
    "# Keep only three variables\n",
    "typhoon_data = typhoon_data[[\"Name\",\"Signal_max\",\"end_date\"]]\n",
    "\n",
    "# Show the data\n",
    "typhoon_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Stock data\n",
    "\n",
    "For stock data, we will calculate the return from the previous trading day.\n",
    "\n",
    "The most notable pandas technique we use here is ```.shift(x)```. \n",
    "This method shifts all rows down by *x* rows.\n",
    "The nice thing about this technique is that you can totally do things\n",
    "like \n",
    "```python\n",
    "stock_data[\"Price\"]/stock_data.shift(1)[\"Price\"] - 1\n",
    "```\n",
    "which gives you all daily return in one single line.\n",
    "\n",
    "Other notable techniques:\n",
    "- **Drop rows with missing values**\n",
    "```python\n",
    "DataFrame.dropna()\n",
    "```\n",
    "- **Convert column(s) to numeric format**\n",
    "```python\n",
    "pd.to_numeric(DataFrame[['column_name']])\n",
    "```\n",
    "Specify `errors='coerce'` to force convert. Any values that is not numeric\n",
    "will be converted to `NaN`.\n",
    "\n",
    "\n",
    "- **Fill in missing dates**: first change the DataFrame's index to a date variable:\n",
    "```python\n",
    "DataFrame.index = pd.DatetimeIndex(DataFrame['date_column'])\n",
    "```\n",
    "Then\n",
    "```python\n",
    "DataFrame.asfreq(freq)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>90d_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-04</th>\n",
       "      <td>1999-01-04</td>\n",
       "      <td>9809.169922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-05</th>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>9891.059570</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.253975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-06</th>\n",
       "      <td>1999-01-06</td>\n",
       "      <td>10233.799805</td>\n",
       "      <td>0.034652</td>\n",
       "      <td>0.209269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-07</th>\n",
       "      <td>1999-01-07</td>\n",
       "      <td>10693.570313</td>\n",
       "      <td>0.044927</td>\n",
       "      <td>0.147619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-08</th>\n",
       "      <td>1999-01-08</td>\n",
       "      <td>10722.700195</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.159863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-09</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-10</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-11</th>\n",
       "      <td>1999-01-11</td>\n",
       "      <td>10634.269531</td>\n",
       "      <td>-0.008247</td>\n",
       "      <td>0.161049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-12</th>\n",
       "      <td>1999-01-12</td>\n",
       "      <td>10711.559570</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.158483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-13</th>\n",
       "      <td>1999-01-13</td>\n",
       "      <td>10273.769531</td>\n",
       "      <td>-0.040871</td>\n",
       "      <td>0.198054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date     Adj Close  daily_return  90d_return\n",
       "Date                                                         \n",
       "1999-01-04 1999-01-04   9809.169922           NaN    0.287275\n",
       "1999-01-05 1999-01-05   9891.059570      0.008348    0.253975\n",
       "1999-01-06 1999-01-06  10233.799805      0.034652    0.209269\n",
       "1999-01-07 1999-01-07  10693.570313      0.044927    0.147619\n",
       "1999-01-08 1999-01-08  10722.700195      0.002724    0.159863\n",
       "1999-01-09        NaT           NaN           NaN         NaN\n",
       "1999-01-10        NaT           NaN           NaN         NaN\n",
       "1999-01-11 1999-01-11  10634.269531     -0.008247    0.161049\n",
       "1999-01-12 1999-01-12  10711.559570      0.007268    0.158483\n",
       "1999-01-13 1999-01-13  10273.769531     -0.040871    0.198054"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import stock data and keep only two variables\n",
    "stock_data = pd.read_csv(\"../Data/hsi.csv\")\n",
    "stock_data = stock_data[[\"Date\",\"Adj Close\"]]\n",
    "\n",
    "# Convert date to pandas datetime format\n",
    "stock_data[\"Date\"] = pd.to_datetime(stock_data[\"Date\"])\n",
    "\n",
    "# Adj Close is NaN on some dates. \n",
    "# Force convert everything to numeric and drop missing.\n",
    "stock_data[\"Adj Close\"] = pd.to_numeric(stock_data[\"Adj Close\"],\n",
    "                                        errors='coerce')\n",
    "stock_data = stock_data.dropna()\n",
    "\n",
    "# Calculate return since the previous trading day\n",
    "stock_data[\"daily_return\"] = (stock_data[\"Adj Close\"] / \n",
    "                              stock_data.shift(1)[\"Adj Close\"]\n",
    "                              - 1)\n",
    "# 90-day future return\n",
    "stock_data[\"90d_return\"] = (stock_data.shift(-90)[\"Adj Close\"] / \n",
    "                              stock_data[\"Adj Close\"]\n",
    "                              - 1)\n",
    "\n",
    "# Use date as the index of the dataframe and fill in missing dates\n",
    "stock_data.index = pd.DatetimeIndex(stock_data[\"Date\"])\n",
    "stock_data = stock_data.asfreq(freq='D')\n",
    "\n",
    "# Show the data\n",
    "stock_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Merge stock and typhoon data\n",
    "\n",
    "We can now merge the stock and typhoon data. To **merge** two DataFrames A and B, use\n",
    "```python\n",
    "DataFrame_A.merge(DataFrame_B, options)\n",
    "```\n",
    "common options include:\n",
    "- `how`: whether the merge keeps all samples from the left DataFrame (A), \n",
    "the right DataFrame (B), a union of the two or intersection. \n",
    "Default is intersection, which means only samples that appear on both DataFrames\n",
    "will be kept.\n",
    "- `left_on` and `right_on`: the name of the columns used to match the two DataFrames.\n",
    "- `left_index` and `right index`: use the DataFrame index instead of a column for the match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>90d_return</th>\n",
       "      <th>Name</th>\n",
       "      <th>Signal_max</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEO</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999-06-07</td>\n",
       "      <td>12837.389648</td>\n",
       "      <td>0.033978</td>\n",
       "      <td>-0.041933</td>\n",
       "      <td>MAGGIE</td>\n",
       "      <td>9</td>\n",
       "      <td>1999-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1999-08-23</td>\n",
       "      <td>13573.660156</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.279657</td>\n",
       "      <td>SAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YORK</td>\n",
       "      <td>10</td>\n",
       "      <td>1999-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YUTU</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2002-09-12</td>\n",
       "      <td>9896.330078</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>-0.031489</td>\n",
       "      <td>HAGUPIT</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2003-07-24</td>\n",
       "      <td>9923.139648</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.255348</td>\n",
       "      <td>IMBUDO</td>\n",
       "      <td>8</td>\n",
       "      <td>2003-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2003-09-03</td>\n",
       "      <td>11102.360352</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.199824</td>\n",
       "      <td>DUJUAN</td>\n",
       "      <td>9</td>\n",
       "      <td>2003-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2004-07-16</td>\n",
       "      <td>12059.200195</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.160692</td>\n",
       "      <td>KOMPASU</td>\n",
       "      <td>8</td>\n",
       "      <td>2004-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2007-08-10</td>\n",
       "      <td>21792.710938</td>\n",
       "      <td>-0.028818</td>\n",
       "      <td>0.240289</td>\n",
       "      <td>PABUK</td>\n",
       "      <td>8</td>\n",
       "      <td>2007-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2008-06-25</td>\n",
       "      <td>22635.160156</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>-0.344376</td>\n",
       "      <td>FENGSHEN</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KAMMURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NURI</td>\n",
       "      <td>9</td>\n",
       "      <td>2008-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2008-09-24</td>\n",
       "      <td>18961.990234</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>-0.273860</td>\n",
       "      <td>HAGUPIT</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOLAVE</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2009-08-05</td>\n",
       "      <td>20494.769531</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>0.068668</td>\n",
       "      <td>GONI</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2009-09-15</td>\n",
       "      <td>20866.369141</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>-0.012835</td>\n",
       "      <td>KOPPU</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NESAT</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOKSURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>18903.199219</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.165432</td>\n",
       "      <td>VICENTE</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>20116.070313</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.126790</td>\n",
       "      <td>KAI-TAK</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>23371.539063</td>\n",
       "      <td>-0.005573</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>USAGI</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>24136.009766</td>\n",
       "      <td>-0.009073</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>KALMAEGI</td>\n",
       "      <td>8</td>\n",
       "      <td>2014-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>24392.789063</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>-0.090376</td>\n",
       "      <td>LINFA</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAIMA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>25852.099609</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.101931</td>\n",
       "      <td>MERBOK</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROKE</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HATO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAKHAR</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KHANUN</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>26932.849609</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>MANGKHUT</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-09-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     Adj Close  daily_return  90d_return      Name  Signal_max  \\\n",
       "2          NaT           NaN           NaN         NaN       LEO           8   \n",
       "8   1999-06-07  12837.389648      0.033978   -0.041933    MAGGIE           9   \n",
       "17  1999-08-23  13573.660156      0.000510    0.279657       SAM           8   \n",
       "25         NaT           NaN           NaN         NaN      YORK          10   \n",
       "30         NaT           NaN           NaN         NaN       CAM           8   \n",
       "52         NaT           NaN           NaN         NaN      UTOR           8   \n",
       "57         NaT           NaN           NaN         NaN      YUTU           8   \n",
       "66  2002-09-12   9896.330078      0.001415   -0.031489   HAGUPIT           8   \n",
       "72  2003-07-24   9923.139648      0.002281    0.255348    IMBUDO           8   \n",
       "80  2003-09-03  11102.360352      0.014847    0.199824    DUJUAN           9   \n",
       "87  2004-07-16  12059.200195      0.010033    0.160692   KOMPASU           8   \n",
       "111 2007-08-10  21792.710938     -0.028818    0.240289     PABUK           8   \n",
       "121 2008-06-25  22635.160156      0.007977   -0.344376  FENGSHEN           8   \n",
       "126        NaT           NaN           NaN         NaN   KAMMURI           8   \n",
       "133        NaT           NaN           NaN         NaN      NURI           9   \n",
       "139 2008-09-24  18961.990234      0.004723   -0.273860   HAGUPIT           8   \n",
       "152        NaT           NaN           NaN         NaN    MOLAVE           9   \n",
       "157 2009-08-05  20494.769531     -0.014505    0.068668      GONI           8   \n",
       "166 2009-09-15  20866.369141     -0.003145   -0.012835     KOPPU           8   \n",
       "190        NaT           NaN           NaN         NaN     NESAT           8   \n",
       "201        NaT           NaN           NaN         NaN   DOKSURI           8   \n",
       "209 2012-07-24  18903.199219     -0.007887    0.165432   VICENTE          10   \n",
       "214 2012-08-17  20116.070313      0.007670    0.126790   KAI-TAK           8   \n",
       "229        NaT           NaN           NaN         NaN      UTOR           8   \n",
       "235 2013-09-23  23371.539063     -0.005573   -0.089945     USAGI           8   \n",
       "245 2014-09-16  24136.009766     -0.009073    0.027812  KALMAEGI           8   \n",
       "251 2015-07-09  24392.789063      0.037260   -0.090376     LINFA           8   \n",
       "263        NaT           NaN           NaN         NaN      NIDA           8   \n",
       "276        NaT           NaN           NaN         NaN     HAIMA           8   \n",
       "282 2017-06-13  25852.099609      0.005604    0.101931    MERBOK           8   \n",
       "286        NaT           NaN           NaN         NaN      ROKE           8   \n",
       "294        NaT           NaN           NaN         NaN      HATO          10   \n",
       "299        NaT           NaN           NaN         NaN    PAKHAR           8   \n",
       "308        NaT           NaN           NaN         NaN    KHANUN           8   \n",
       "328 2018-09-17  26932.849609     -0.012957    0.022234  MANGKHUT          10   \n",
       "\n",
       "      end_date  \n",
       "2   1999-05-02  \n",
       "8   1999-06-07  \n",
       "17  1999-08-23  \n",
       "25  1999-09-16  \n",
       "30  1999-09-26  \n",
       "52  2001-07-06  \n",
       "57  2001-07-25  \n",
       "66  2002-09-12  \n",
       "72  2003-07-24  \n",
       "80  2003-09-03  \n",
       "87  2004-07-16  \n",
       "111 2007-08-10  \n",
       "121 2008-06-25  \n",
       "126 2008-08-06  \n",
       "133 2008-08-23  \n",
       "139 2008-09-24  \n",
       "152 2009-07-19  \n",
       "157 2009-08-05  \n",
       "166 2009-09-15  \n",
       "190 2011-09-29  \n",
       "201 2012-06-30  \n",
       "209 2012-07-24  \n",
       "214 2012-08-17  \n",
       "229 2013-08-14  \n",
       "235 2013-09-23  \n",
       "245 2014-09-16  \n",
       "251 2015-07-09  \n",
       "263 2016-08-02  \n",
       "276 2016-10-21  \n",
       "282 2017-06-13  \n",
       "286 2017-07-23  \n",
       "294 2017-08-23  \n",
       "299 2017-08-27  \n",
       "308 2017-10-15  \n",
       "328 2018-09-17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = stock_data.merge(typhoon_data, how='right', left_index=True, right_on='end_date')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless the typhoon's signal went below No. 8 before market opens, no stock data will be available for the given `end_date`. In this case we use the return from the next trading day.\n",
    "\n",
    "First we extract the list of such typhoons. We can do that by using the ```.isnull()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Signal_max</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEO</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>YORK</td>\n",
       "      <td>10</td>\n",
       "      <td>1999-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>YUTU</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>KAMMURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NURI</td>\n",
       "      <td>9</td>\n",
       "      <td>2008-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>MOLAVE</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NESAT</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>DOKSURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>NIDA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>HAIMA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ROKE</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>HATO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>PAKHAR</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>KHANUN</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-10-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Signal_max   end_date\n",
       "2        LEO           8 1999-05-02\n",
       "25      YORK          10 1999-09-16\n",
       "30       CAM           8 1999-09-26\n",
       "52      UTOR           8 2001-07-06\n",
       "57      YUTU           8 2001-07-25\n",
       "126  KAMMURI           8 2008-08-06\n",
       "133     NURI           9 2008-08-23\n",
       "152   MOLAVE           9 2009-07-19\n",
       "190    NESAT           8 2011-09-29\n",
       "201  DOKSURI           8 2012-06-30\n",
       "229     UTOR           8 2013-08-14\n",
       "263     NIDA           8 2016-08-02\n",
       "276    HAIMA           8 2016-10-21\n",
       "286     ROKE           8 2017-07-23\n",
       "294     HATO          10 2017-08-23\n",
       "299   PAKHAR           8 2017-08-27\n",
       "308   KHANUN           8 2017-10-15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_na = merged_data[merged_data['Adj Close'].isnull()]\n",
    "merged_data_na = merged_data_na[[\"Name\",\"Signal_max\",\"end_date\"]]\n",
    "merged_data_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we merge in stock information from the next day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>90d_return</th>\n",
       "      <th>Name</th>\n",
       "      <th>Signal_max</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-05-03</td>\n",
       "      <td>13337.070313</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>LEO</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1999-09-17</td>\n",
       "      <td>13484.839844</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.180423</td>\n",
       "      <td>YORK</td>\n",
       "      <td>10</td>\n",
       "      <td>1999-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1999-09-27</td>\n",
       "      <td>12760.459961</td>\n",
       "      <td>-0.020842</td>\n",
       "      <td>0.271798</td>\n",
       "      <td>CAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2001-07-26</td>\n",
       "      <td>12039.820313</td>\n",
       "      <td>-0.014269</td>\n",
       "      <td>-0.073479</td>\n",
       "      <td>YUTU</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2008-08-07</td>\n",
       "      <td>22104.199219</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>-0.315505</td>\n",
       "      <td>KAMMURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NURI</td>\n",
       "      <td>9</td>\n",
       "      <td>2008-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2009-07-20</td>\n",
       "      <td>19502.369141</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.159439</td>\n",
       "      <td>MOLAVE</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>17592.410156</td>\n",
       "      <td>-0.023244</td>\n",
       "      <td>0.189026</td>\n",
       "      <td>NESAT</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOKSURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>22539.250000</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.028408</td>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>21739.119141</td>\n",
       "      <td>-0.017625</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAIMA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>26846.830078</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.086808</td>\n",
       "      <td>ROKE</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>27518.599609</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.116935</td>\n",
       "      <td>HATO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>27863.289063</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.108969</td>\n",
       "      <td>PAKHAR</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>28692.800781</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.097788</td>\n",
       "      <td>KHANUN</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-10-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     Adj Close  daily_return  90d_return     Name  Signal_max  \\\n",
       "2   1999-05-03  13337.070313      0.000290    0.001467      LEO           8   \n",
       "25  1999-09-17  13484.839844      0.004039    0.180423     YORK          10   \n",
       "30  1999-09-27  12760.459961     -0.020842    0.271798      CAM           8   \n",
       "52         NaT           NaN           NaN         NaN     UTOR           8   \n",
       "57  2001-07-26  12039.820313     -0.014269   -0.073479     YUTU           8   \n",
       "126 2008-08-07  22104.199219      0.007036   -0.315505  KAMMURI           8   \n",
       "133        NaT           NaN           NaN         NaN     NURI           9   \n",
       "152 2009-07-20  19502.369141      0.037048    0.159439   MOLAVE           9   \n",
       "190 2011-09-30  17592.410156     -0.023244    0.189026    NESAT           8   \n",
       "201        NaT           NaN           NaN         NaN  DOKSURI           8   \n",
       "229 2013-08-15  22539.250000     -0.000083    0.028408     UTOR           8   \n",
       "263 2016-08-03  21739.119141     -0.017625    0.031919     NIDA           8   \n",
       "276        NaT           NaN           NaN         NaN    HAIMA           8   \n",
       "286 2017-07-24  26846.830078      0.005270    0.086808     ROKE           8   \n",
       "294 2017-08-24  27518.599609      0.004267    0.116935     HATO          10   \n",
       "299 2017-08-28  27863.289063      0.000543    0.108969   PAKHAR           8   \n",
       "308 2017-10-16  28692.800781      0.007598    0.097788   KHANUN           8   \n",
       "\n",
       "      end_date  \n",
       "2   1999-05-02  \n",
       "25  1999-09-16  \n",
       "30  1999-09-26  \n",
       "52  2001-07-06  \n",
       "57  2001-07-25  \n",
       "126 2008-08-06  \n",
       "133 2008-08-23  \n",
       "152 2009-07-19  \n",
       "190 2011-09-29  \n",
       "201 2012-06-30  \n",
       "229 2013-08-14  \n",
       "263 2016-08-02  \n",
       "276 2016-10-21  \n",
       "286 2017-07-23  \n",
       "294 2017-08-23  \n",
       "299 2017-08-27  \n",
       "308 2017-10-15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part2 = stock_data.tshift(-1).merge(merged_data_na, how='right', \n",
    "                                    left_index=True, right_on='end_date')\n",
    "part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If return is still missing after this step, it must be the case that at least two days have passed since Signal No. 8 was lowered. We will ignore such instances.\n",
    "\n",
    "To append one DataFrame at the bottom of another, use ```.append()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>90d_return</th>\n",
       "      <th>Name</th>\n",
       "      <th>Signal_max</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999-06-07</td>\n",
       "      <td>12837.389648</td>\n",
       "      <td>0.033978</td>\n",
       "      <td>-0.041933</td>\n",
       "      <td>MAGGIE</td>\n",
       "      <td>9</td>\n",
       "      <td>1999-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1999-08-23</td>\n",
       "      <td>13573.660156</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.279657</td>\n",
       "      <td>SAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2002-09-12</td>\n",
       "      <td>9896.330078</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>-0.031489</td>\n",
       "      <td>HAGUPIT</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2003-07-24</td>\n",
       "      <td>9923.139648</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.255348</td>\n",
       "      <td>IMBUDO</td>\n",
       "      <td>8</td>\n",
       "      <td>2003-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2003-09-03</td>\n",
       "      <td>11102.360352</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.199824</td>\n",
       "      <td>DUJUAN</td>\n",
       "      <td>9</td>\n",
       "      <td>2003-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2004-07-16</td>\n",
       "      <td>12059.200195</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.160692</td>\n",
       "      <td>KOMPASU</td>\n",
       "      <td>8</td>\n",
       "      <td>2004-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2007-08-10</td>\n",
       "      <td>21792.710938</td>\n",
       "      <td>-0.028818</td>\n",
       "      <td>0.240289</td>\n",
       "      <td>PABUK</td>\n",
       "      <td>8</td>\n",
       "      <td>2007-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2008-06-25</td>\n",
       "      <td>22635.160156</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>-0.344376</td>\n",
       "      <td>FENGSHEN</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2008-09-24</td>\n",
       "      <td>18961.990234</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>-0.273860</td>\n",
       "      <td>HAGUPIT</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2009-08-05</td>\n",
       "      <td>20494.769531</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>0.068668</td>\n",
       "      <td>GONI</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2009-09-15</td>\n",
       "      <td>20866.369141</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>-0.012835</td>\n",
       "      <td>KOPPU</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>18903.199219</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.165432</td>\n",
       "      <td>VICENTE</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>20116.070313</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.126790</td>\n",
       "      <td>KAI-TAK</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>23371.539063</td>\n",
       "      <td>-0.005573</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>USAGI</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>24136.009766</td>\n",
       "      <td>-0.009073</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>KALMAEGI</td>\n",
       "      <td>8</td>\n",
       "      <td>2014-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>24392.789063</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>-0.090376</td>\n",
       "      <td>LINFA</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>25852.099609</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.101931</td>\n",
       "      <td>MERBOK</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>26932.849609</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>MANGKHUT</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-05-03</td>\n",
       "      <td>13337.070313</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>LEO</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1999-09-17</td>\n",
       "      <td>13484.839844</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.180423</td>\n",
       "      <td>YORK</td>\n",
       "      <td>10</td>\n",
       "      <td>1999-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1999-09-27</td>\n",
       "      <td>12760.459961</td>\n",
       "      <td>-0.020842</td>\n",
       "      <td>0.271798</td>\n",
       "      <td>CAM</td>\n",
       "      <td>8</td>\n",
       "      <td>1999-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2001-07-26</td>\n",
       "      <td>12039.820313</td>\n",
       "      <td>-0.014269</td>\n",
       "      <td>-0.073479</td>\n",
       "      <td>YUTU</td>\n",
       "      <td>8</td>\n",
       "      <td>2001-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2008-08-07</td>\n",
       "      <td>22104.199219</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>-0.315505</td>\n",
       "      <td>KAMMURI</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2009-07-20</td>\n",
       "      <td>19502.369141</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.159439</td>\n",
       "      <td>MOLAVE</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>17592.410156</td>\n",
       "      <td>-0.023244</td>\n",
       "      <td>0.189026</td>\n",
       "      <td>NESAT</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>22539.250000</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.028408</td>\n",
       "      <td>UTOR</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>21739.119141</td>\n",
       "      <td>-0.017625</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>26846.830078</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.086808</td>\n",
       "      <td>ROKE</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>27518.599609</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.116935</td>\n",
       "      <td>HATO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>27863.289063</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.108969</td>\n",
       "      <td>PAKHAR</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>28692.800781</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.097788</td>\n",
       "      <td>KHANUN</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-10-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     Adj Close  daily_return  90d_return      Name  Signal_max  \\\n",
       "8   1999-06-07  12837.389648      0.033978   -0.041933    MAGGIE           9   \n",
       "17  1999-08-23  13573.660156      0.000510    0.279657       SAM           8   \n",
       "66  2002-09-12   9896.330078      0.001415   -0.031489   HAGUPIT           8   \n",
       "72  2003-07-24   9923.139648      0.002281    0.255348    IMBUDO           8   \n",
       "80  2003-09-03  11102.360352      0.014847    0.199824    DUJUAN           9   \n",
       "87  2004-07-16  12059.200195      0.010033    0.160692   KOMPASU           8   \n",
       "111 2007-08-10  21792.710938     -0.028818    0.240289     PABUK           8   \n",
       "121 2008-06-25  22635.160156      0.007977   -0.344376  FENGSHEN           8   \n",
       "139 2008-09-24  18961.990234      0.004723   -0.273860   HAGUPIT           8   \n",
       "157 2009-08-05  20494.769531     -0.014505    0.068668      GONI           8   \n",
       "166 2009-09-15  20866.369141     -0.003145   -0.012835     KOPPU           8   \n",
       "209 2012-07-24  18903.199219     -0.007887    0.165432   VICENTE          10   \n",
       "214 2012-08-17  20116.070313      0.007670    0.126790   KAI-TAK           8   \n",
       "235 2013-09-23  23371.539063     -0.005573   -0.089945     USAGI           8   \n",
       "245 2014-09-16  24136.009766     -0.009073    0.027812  KALMAEGI           8   \n",
       "251 2015-07-09  24392.789063      0.037260   -0.090376     LINFA           8   \n",
       "282 2017-06-13  25852.099609      0.005604    0.101931    MERBOK           8   \n",
       "328 2018-09-17  26932.849609     -0.012957    0.022234  MANGKHUT          10   \n",
       "2   1999-05-03  13337.070313      0.000290    0.001467       LEO           8   \n",
       "25  1999-09-17  13484.839844      0.004039    0.180423      YORK          10   \n",
       "30  1999-09-27  12760.459961     -0.020842    0.271798       CAM           8   \n",
       "57  2001-07-26  12039.820313     -0.014269   -0.073479      YUTU           8   \n",
       "126 2008-08-07  22104.199219      0.007036   -0.315505   KAMMURI           8   \n",
       "152 2009-07-20  19502.369141      0.037048    0.159439    MOLAVE           9   \n",
       "190 2011-09-30  17592.410156     -0.023244    0.189026     NESAT           8   \n",
       "229 2013-08-15  22539.250000     -0.000083    0.028408      UTOR           8   \n",
       "263 2016-08-03  21739.119141     -0.017625    0.031919      NIDA           8   \n",
       "286 2017-07-24  26846.830078      0.005270    0.086808      ROKE           8   \n",
       "294 2017-08-24  27518.599609      0.004267    0.116935      HATO          10   \n",
       "299 2017-08-28  27863.289063      0.000543    0.108969    PAKHAR           8   \n",
       "308 2017-10-16  28692.800781      0.007598    0.097788    KHANUN           8   \n",
       "\n",
       "      end_date  \n",
       "8   1999-06-07  \n",
       "17  1999-08-23  \n",
       "66  2002-09-12  \n",
       "72  2003-07-24  \n",
       "80  2003-09-03  \n",
       "87  2004-07-16  \n",
       "111 2007-08-10  \n",
       "121 2008-06-25  \n",
       "139 2008-09-24  \n",
       "157 2009-08-05  \n",
       "166 2009-09-15  \n",
       "209 2012-07-24  \n",
       "214 2012-08-17  \n",
       "235 2013-09-23  \n",
       "245 2014-09-16  \n",
       "251 2015-07-09  \n",
       "282 2017-06-13  \n",
       "328 2018-09-17  \n",
       "2   1999-05-02  \n",
       "25  1999-09-16  \n",
       "30  1999-09-26  \n",
       "57  2001-07-25  \n",
       "126 2008-08-06  \n",
       "152 2009-07-19  \n",
       "190 2011-09-29  \n",
       "229 2013-08-14  \n",
       "263 2016-08-02  \n",
       "286 2017-07-23  \n",
       "294 2017-08-23  \n",
       "299 2017-08-27  \n",
       "308 2017-10-15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1 = merged_data[merged_data['Adj Close'].notnull()]\n",
    "part2 = part2.dropna()\n",
    "\n",
    "# Final data\n",
    "data_w_typhoon = part1.append(part2)\n",
    "data_w_typhoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Statistical Analysis\n",
    "\n",
    "Finally we can perform some statistical analysis. We will start with comparing the daily return on the first trading day after a typhoon versus all other days.\n",
    "\n",
    "### B1. Statistical Tests\n",
    "\n",
    "```scipy.stats``` contains many of the common tests. Noteable ones include:\n",
    "- **T-test**: ```ttest_ind(A,B)```.\n",
    "- **Median Test**: ```median_test(A,B)```. \n",
    "- **Mann-Whitney rank test**: ```mannwhitneyu(A,B)```. A non-parametric test on whether A and B have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily return after typhoon: 0.00110868378018\n",
      "Daily return w/o typhoon:   0.000309506782828\n",
      "----------------------------------------------------------------------\n",
      "Statistical Tests:      (statistic, p-value)\n",
      "T-test:                 (0.29787470527592164, 0.76581139987855984)\n",
      "Mood's median test:     (0.13067290126128978, 0.71773536963473861)\n",
      "Mann-Whitney rank test: (74545.0, 0.44469071155447942)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Stock data without typhoon. '~' means 'not'.\n",
    "data_wo_typhoon = stock_data[~stock_data['Date'].isin(data_w_typhoon['Date'])].dropna()\n",
    "\n",
    "# Mean daily returns\n",
    "print(\"Daily return after typhoon:\",data_w_typhoon['daily_return'].mean())\n",
    "print(\"Daily return w/o typhoon:  \",data_wo_typhoon['daily_return'].mean())\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Statistical Tests:      (statistic, p-value)\")\n",
    "\n",
    "# T-test\n",
    "print(\"T-test:                \",stats.ttest_ind(data_w_typhoon['daily_return'],\n",
    "                data_wo_typhoon['daily_return'])[0:2])\n",
    "\n",
    "# Mood's median test\n",
    "print(\"Mood's median test:    \",stats.median_test(data_w_typhoon['daily_return'],\n",
    "                data_wo_typhoon['daily_return'])[0:2])\n",
    "\n",
    "# Mann-Whitney test\n",
    "print(\"Mann-Whitney rank test:\",stats.mannwhitneyu(data_w_typhoon['daily_return'],\n",
    "                data_wo_typhoon['daily_return'])[0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out the stock market on average performs better right after a typhoon! The difference is not statistically significant though.\n",
    "\n",
    "### B2. Regression\n",
    "\n",
    "We can also run a regression. Note that running a regression with a single dummy variable is identical to running a T-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.00079917699735186675, intercept=0.00030950678282767185, rvalue=0.0042514119089415081, pvalue=0.76581139987856006, stderr=0.002682930048093841)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Signal max = 0 if no typhoon\n",
    "data_wo_typhoon['Signal_max'] = 0\n",
    "data_whole = data_w_typhoon.append(data_wo_typhoon)\n",
    "\n",
    "# Convert Signal_max to a dummy variable called 'typhoon'\n",
    "data_whole[\"typhoon\"] = 0\n",
    "data_whole.loc[data_whole['Signal_max']>=8,'typhoon'] = 1\n",
    "\n",
    "# scipy OLS\n",
    "stats.linregress(data_whole['typhoon'],data_whole['daily_return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer output that is more in line with what a statistical package like Stata would give you, use ```statsmodels``` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>daily_return</td>   <th>  R-squared:         </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>  -0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td> 0.08873</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Jul 2019</td> <th>  Prob (F-statistic):</th>   <td> 0.766</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:05:13</td>     <th>  Log-Likelihood:    </th>  <td>  13693.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4911</td>      <th>  AIC:               </th> <td>-2.738e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4909</td>      <th>  BIC:               </th> <td>-2.737e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    0.0003</td> <td>    0.000</td> <td>    1.452</td> <td> 0.147</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>typhoon</th> <td>    0.0008</td> <td>    0.003</td> <td>    0.298</td> <td> 0.766</td> <td>   -0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>755.636</td> <th>  Durbin-Watson:     </th> <td>   2.004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>12263.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.133</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.737</td>  <th>  Cond. No.          </th> <td>    12.6</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           daily_return   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                   0.08873\n",
       "Date:                Wed, 31 Jul 2019   Prob (F-statistic):              0.766\n",
       "Time:                        08:05:13   Log-Likelihood:                 13693.\n",
       "No. Observations:                4911   AIC:                        -2.738e+04\n",
       "Df Residuals:                    4909   BIC:                        -2.737e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0003      0.000      1.452      0.147      -0.000       0.001\n",
       "typhoon        0.0008      0.003      0.298      0.766      -0.004       0.006\n",
       "==============================================================================\n",
       "Omnibus:                      755.636   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12263.021\n",
       "Skew:                           0.133   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.737   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodel OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# statsmodel does not add the constant by default, so add manually\n",
    "results = sm.OLS(data_whole['daily_return'],\n",
    "                 sm.add_constant(data_whole['typhoon'])).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As as a statistical package, ```statsmodels``` have many of the common procedures built in. For example, we can correct for serial correlation by computing the Newey-West Standard Errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>daily_return</td>   <th>  R-squared:         </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>  -0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>  0.1540</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Jul 2019</td> <th>  Prob (F-statistic):</th>   <td> 0.695</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:05:13</td>     <th>  Log-Likelihood:    </th>  <td>  13693.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4911</td>      <th>  AIC:               </th> <td>-2.738e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4909</td>      <th>  BIC:               </th> <td>-2.737e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HAC</td>       <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    0.0003</td> <td>    0.000</td> <td>    1.482</td> <td> 0.139</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>typhoon</th> <td>    0.0008</td> <td>    0.002</td> <td>    0.392</td> <td> 0.695</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>755.636</td> <th>  Durbin-Watson:     </th> <td>   2.004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>12263.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.133</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.737</td>  <th>  Cond. No.          </th> <td>    12.6</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           daily_return   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                    0.1540\n",
       "Date:                Wed, 31 Jul 2019   Prob (F-statistic):              0.695\n",
       "Time:                        08:05:13   Log-Likelihood:                 13693.\n",
       "No. Observations:                4911   AIC:                        -2.738e+04\n",
       "Df Residuals:                    4909   BIC:                        -2.737e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HAC                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0003      0.000      1.482      0.139      -0.000       0.001\n",
       "typhoon        0.0008      0.002      0.392      0.695      -0.003       0.005\n",
       "==============================================================================\n",
       "Omnibus:                      755.636   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12263.021\n",
       "Skew:                           0.133   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.737   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 5 lags and without small sample correction\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Newey-West Standard Errors. Note that we are using the results\n",
    "# from the previous regression.\n",
    "nw = results.get_robustcov_results(cov_type='HAC',maxlags=5)\n",
    "nw.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another idea: what about buying HSI right after a typhoon? Let us compare the mean return of buying right after a typhoon versus that of other days. We will assume a fixed 90-day holding period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>90d_return</td>    <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td> 0.250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:05:13</td>     <th>  Log-Likelihood:    </th> <td>  2659.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4911</td>      <th>  AIC:               </th> <td>  -5314.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4909</td>      <th>  BIC:               </th> <td>  -5301.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HAC</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    0.0269</td> <td>    0.005</td> <td>    5.510</td> <td> 0.000</td> <td>    0.017</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>typhoon</th> <td>    0.0263</td> <td>    0.023</td> <td>    1.150</td> <td> 0.250</td> <td>   -0.019</td> <td>    0.071</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>195.088</td> <th>  Durbin-Watson:     </th> <td>   0.037</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 471.655</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.214</td>  <th>  Prob(JB):          </th> <td>3.81e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.457</td>  <th>  Cond. No.          </th> <td>    12.6</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             90d_return   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                  0.000\n",
       "Method:                 Least Squares   F-statistic:                     1.322\n",
       "Date:                Wed, 31 Jul 2019   Prob (F-statistic):              0.250\n",
       "Time:                        08:05:13   Log-Likelihood:                 2659.1\n",
       "No. Observations:                4911   AIC:                            -5314.\n",
       "Df Residuals:                    4909   BIC:                            -5301.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HAC                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0269      0.005      5.510      0.000       0.017       0.036\n",
       "typhoon        0.0263      0.023      1.150      0.250      -0.019       0.071\n",
       "==============================================================================\n",
       "Omnibus:                      195.088   Durbin-Watson:                   0.037\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              471.655\n",
       "Skew:                           0.214   Prob(JB):                    3.81e-103\n",
       "Kurtosis:                       4.457   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 5 lags and without small sample correction\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want Newey-West standard errors to begin with, this is how:\n",
    "results = sm.OLS(data_whole['90d_return'],\n",
    "              sm.add_constant(data_whole['typhoon'])\n",
    "             ).fit(cov_type='HAC',cov_kwds={'maxlags':5})\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buying after typhoon gives us on average a 2.6% higher return over 3 months! To bad it is not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. That's It? No Significant Result?\n",
    "\n",
    "Let us plot the distribution of returns for days with typhoon and without:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f485888b860>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7f4858822d68>], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4858b51eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "data_whole.hist(column='90d_return',by='typhoon')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does look like return is higher after a typhoon. Thinking about it, a Signal 8 typhoon is often quite predestrian---people actually go out for breakfast and movies. What if we focus only on the strongest typhoons? I leave this as an exercise for you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
